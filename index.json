[{"content":" 本文是PhysX物理引擎 这个系列的番外篇，其实要弄明白一个3D数学问题：如何处理父节点带有非均匀缩放和旋转时，子节点的最终大小和形态。 问题源自笔者在修改物理引擎为其添加scale属性时遇到的一个bug。解决后对WorldScale为什么叫做LossyScale、空间变换和基变换有了更深的理解。\n背景 PhysX引擎中，场景内的Actor之间并没有父子层级关系，仅有的层级是Shape可以绑定到Actor作为子节点。 PhysX引擎中并没有Scale的概念，即PxTransform只包含Position和Rotation，而大小只反映在最底层Shape的尺寸上（比如球形碰撞盒有半径这个属性）。所以设置缩放比例的实现方式是改变物体尺寸。 问题的出现 Actor下可以有若干Shape，这里只讨论一个Shape。增加属性Actor.Scale，修改该属性时要保证Shape.Dimension的正确性。\nclassDiagram direction LR class Actor { PxVec3 Position PxQuat Rotation PxVec3 Scale } class Shape { PxVec3 LocalPosition PxQuat LocalRotation PxVec3 OriginalDimension PxVec3 Dimension } Actor o-- Shape 经实践，更方便的方式是记录Shape的初始尺寸OriginalDimension，然后乘上改变Actor.Scale后对应Shape的“缩放系数”。而不是为了节省存储通过Actor.Scale改变前后的比例来计算。总之，问题简化为实现GetShapeScale()。\nShape.Dimension = Shape.OriginalDimension * GetShapeScale(); 当Shape相对Actor没有旋转，即Shape.LocalRotation = (0,0,0,1)时，容易发现：\nPxVec3 GetShapeScale() { return actor.Scale; } 但是当同时存在旋转和非均匀缩放呢？简单来说，当Actor.Scale=(1,4,1)，而Shape绕z轴转了90度，那么预期的结果应该是(4,1,1)，即Shape相对于自己在横向上扩大到2倍。若绕z轴转了45度，那么预期的结果是(2,2,1)。要如何达到这种效果呢？\n似是而非的算法 一个很自然的想法是，要达到上面的效果，其实是将Actor.Scale像方向矢量那样旋转到Shape空间内。\nPxVec3 GetShapeScale() { PxTransform shapeSpace = shape-\u0026gt;getLocalPose(); return shapeSpace-\u0026gt;rotate(actor.Scale); } 然而反例是：actorScale=(1,1,1)经过旋转后可能不再是(1,1,1)，即Shape叠加了一个缩放。这是与事实违背的。针对(1,1,1)特殊处理也并不正确，因为对于任意(X,Y,Z)，总有一种旋转让其某个分量为0。\n这种算法的错误之处在最后一节会额外讨论。\n正确的算法 在Unity的文档中，对于Transform.LossyScale这样说明：\nThe global scale of the object (Read Only).\nPlease note that if you have a parent transform with scale and a child that is arbitrarily rotated, the scale will be skewed. Thus scale can not be represented correctly in a 3 component vector but only a 3x3 matrix. Such a representation is quite inconvenient to work with however. lossyScale is a convenience property that attempts to match the actual world scale as much as it can. If your objects are not skewed the value will be completely correct and most likely the value will not be very different if it contains skew too.\n理解，但不完全理解。直到找来源码分析了一番。去粗取精，根据代码提炼出公式：\n$$ R_{world}=R_1R_2\u0026hellip;R_N $$ $$ W_{world}=R_1S_1R_2S_2\u0026hellip;R_NS_N $$ $$ S_{world}=R_{world}^{-1}W_{world} $$ $$ s = diag(S_{world}) $$\n上式中，\\(1\u0026hellip;N\\)是根节点到叶子节点的编号，所有矩阵均采用列优先矩阵。\\(R_i\\)是只包含自身旋转信息的3x3旋转矩阵。\\(S_i\\)是质保函自身缩放信息的3x3对角矩阵。最终结果\\(s\\)是3x1列矢量，取自\\(S_{world}\\)的对角线元素。\n算法推导与解释 为什么是这样呢？这要从TRS变换矩阵说起。在3D中间中的姿态、运动和坐标系都可以用矩阵表达。 一般\\(T\\)表示位移，\\(R\\)表示旋转，\\(S\\) 表示缩放。\n贴心提示：\n用欧拉角表示则需要规定旋转轴次序否则有歧义（感兴趣可以搜索万向节死锁）。经过实验Unity使用YXZ，即对于\\((\\theta_x,\\theta_y,\\theta_z)\\)，先按照Y轴转 \\(\\theta_y\\) ，再按照转动后的X轴转\\(\\theta_x\\)，再按照转动后的Z轴转\\(\\theta_z\\)。 有时使用4x4而不是3x3矩阵只是一个数学上的技巧，为了让所有变换都可以用矩阵乘法串联起来。 有时使用分块矩阵也只是一个数学上的技巧，为了简化公式发现规律。 对于列优先矩阵，将列矢量\\(v_1\\)先按照\\(M_1\\)再按照\\(M_2\\)变换到\\(v_2\\)写作\\(v_2=M_2M_1v_1\\)。 更多资料如《游戏引擎架构》、任何讲解3D游戏开发或图形学的书籍。 $$ T= \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; Tx \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; Ty \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; Tz \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}= \\begin{pmatrix} I \u0026amp; \\bar{T}\\\\ 0 \u0026amp; 0 \\end{pmatrix} $$\n$$ R_x= \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; \\cos\\theta_x \u0026amp; -\\sin\\theta_x \u0026amp; 0 \\\\ 0 \u0026amp; \\sin\\theta_x \u0026amp; \\cos\\theta_x \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} $$\n$$ R_y= \\begin{pmatrix} \\cos\\theta_y \u0026amp; 0 \u0026amp; \\sin\\theta_y \u0026amp; 0 \\\\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\\\ -\\sin\\theta_y \u0026amp; 0 \u0026amp; \\cos\\theta_y \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} $$\n$$ R_z= \\begin{pmatrix} \\cos\\theta_z \u0026amp; -\\sin\\theta_z \u0026amp; 0 \u0026amp; 0 \\\\ \\sin\\theta_z \u0026amp; \\cos\\theta_z \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} $$\n$$ R = R_zR_xR_y= \\begin{pmatrix} r_{11} \u0026amp; r_{12} \u0026amp; r_{13} \u0026amp; 0 \\\\ r_{21} \u0026amp; r_{22} \u0026amp; r_{23} \u0026amp; 0 \\\\ r_{31} \u0026amp; r_{32} \u0026amp; r_{33} \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}= \\begin{pmatrix} \\bar{R} \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{pmatrix} $$\n$$ S= \\begin{pmatrix} s_x \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; s_y \u0026amp; 0 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; s_z \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}= \\begin{pmatrix} \\bar{S} \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{pmatrix} $$\n则对于一个节点，其本地坐标系的TRS变换矩阵可以写作：\n$$ M=\\begin{pmatrix} r_{11}S_x \u0026amp; r_{12}S_y \u0026amp; r_{13}S_z \u0026amp; T_x \\\\ r_{21}S_x \u0026amp; r_{22}S_y \u0026amp; r_{23}S_z \u0026amp; T_y \\\\ r_{31}S_x \u0026amp; r_{32}S_y \u0026amp; r_{33}S_z \u0026amp; T_z \\\\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix}= \\begin{pmatrix} \\bar{R}\\bar{S} \u0026amp; \\bar{T} \\\\ 0 \u0026amp; 1 \\end{pmatrix} $$\n则对于父子节点\\(M_1\\)中的子节点\\(M_2\\)，其相对于世界坐标系的变换矩阵可以写作：\n$$ M=M_2M_1= \\begin{pmatrix} \\bar{R_2}\\bar{S_2} \u0026amp; \\bar{T_2} \\\\ 0 \u0026amp; 1 \\end{pmatrix} \\begin{pmatrix} \\bar{R_1}\\bar{S_1} \u0026amp; \\bar{T_1} \\\\ 0 \u0026amp; 1 \\end{pmatrix}= \\begin{pmatrix} \\bar{R_2}\\bar{S_2}\\bar{R_1}\\bar{S_1} \u0026amp; \\bar{R_2}\\bar{S_2}\\bar{T_1}+\\bar{T_2} \\\\ 0 \u0026amp; 1 \\end{pmatrix} $$\n从另一个角度思考，若要将\\(M\\)拆分成TRS三个分量，是否就对应世界坐标系下的位移、旋转、缩放（全局缩放正是我们所需要的）呢？容易观察到全局位移是：\n$$ T_{world}= \\begin{pmatrix} \\bar{R_2}\\bar{S_2}\\bar{T_1}+\\bar{T_2} \\end{pmatrix} $$\n而全局旋转由于其物理意义，必然是：\n$$ R_{world}= \\bar{R_2}\\bar{R_1} $$\n则全局缩放只能是：\n$$ S_{world}=R_{world}^{-1}\\bar{R_2}\\bar{S_2}\\bar{R_1}\\bar{S_1}=(\\bar{R}_1^{-1}\\bar{S_2}\\bar{R_1})\\bar{S_1} $$\n一般来说，\\(S_{world}\\)是一个非对角矩阵，即主对角线之外也有非零值。若只将主对角线元素取出来作为scale，则缩放信息是有损的，这便是Unity中LossyScale名字的由来。\n当父节点是均匀缩放时（即\\(\\bar{S_2}=s_2I\\)），缩放系数可以化简为\\(S_{world}=\\bar{S_2}\\bar{S_1}=[s_x,s_y,s_z]^T\\)，则整体世界变换可以独立分解为TRS三个维度分别做世界变换的组合！而且此时\\(S_{world}\\)是一个对角矩阵，即LossyScale包含了完整的缩放信息。\n$$ M_{world}=T_{world}R_{world}S_{world} $$\n问题的终结 回到最初的问题上来，对Actor设置缩放时要更新所属Shape的尺寸，为此要实现的GetShapeScale()完整版：\nShape.Dimension = Shape.OriginalDimension * GetShapeScale(); PhysXVec3 GetShapeScale() { PxQuat worldRot = actor.Rotation * shapeTransform.q; PxMat33 inverseWorldRotMat = PxMat33(worldRot.getConjugate()); PxMat33 localRotMat = PxMat33(shapeTransform.q); PxMat33 actorRotMat = PxMat33(actor.Rotation); PxMat33 actorScaleMat = PxMat33().createDiagonal(actor.Scale); PxMat33 worldRotAndScaleMat = actorRotMat * actorScaleMat * localRotMat /* * localScaleMat*/; // localScaleMat is always Identity Matrix, so we omit it PxMat33 worldScaleMat = inverseWorldRotMat * worldRotAndScaleMat; PhysXVec3 worldscale = PhysXVec3(worldScaleMat[0][0], worldScaleMat[1][1], worldScaleMat[2][2]); // can have extra logic to make sure all values in worldscale are non-zero return worldscale; } 额外的讨论 已知正确的算法是：\n$$ S_{world}=(\\bar{R}_1^{-1}\\bar{S_2}\\bar{R_1})\\bar{S_1} $$\n而似是而非的算法其实是：\n$$ S_{world}=(\\bar{R_1}s_2)\\bar{S_1} $$\n本质错误在于：\n正确的算法是将缩放本身视为一个空间变换\\(S_2\\)，进行基变换。 错误的算法是将缩放系数视为一个普通矢量\\(s_2\\) ，进行空间变换。 这些在大一的课堂上早已学过。往往正向解释很简单，难的是反向思考，即遇到实际问题怎么选择合适的概念去解决。\n纸上得来终觉浅，绝知此事要躬行。\n","permalink":"https://pps43.github.io/posts/thinking_of_lossyscale/","summary":"本文是PhysX物理引擎 这个系列的番外篇，其实要弄明白一个3D数学问题：如何处理父节点带有非均匀缩放和旋转时，子节点的最终大小和形态。 问题源","title":"深入 LossyScale"},{"content":"这本书带给我的，除了诸多耳熟能详的作品背后的逸闻趣事、诸位大师的才华风貌，还有不少对创作思路、团队协作、宣传发行的启发，相信能常看常新。同时这本书里记录的东西，让人有一种难以名状的触动。一定要形容的话，可以说是一种谁也抑制不了的、忍不住要生长的气魄 1。\n这种气魄和是否是“天才”无关。“才能这种东西，本来就是该靠自己挖掘创造的。我也不是什么天才，我只是比任何人都拼命工作，一步一个脚印走过来了。那帮懒惰的人只顾在山脚念叨着：谁叫那家伙是天才。开什么玩笑……” 2。\n那么，这些人类究竟是抱着怎样的信念，可以如此不知疲倦的创作，打磨，再创作的呢？也许这一切可以从影响宫老先生一生的一本书中找到答案 3。而那个答案，足以让每个还有赤子之心的人相见恨晚。总之，先让我们回到铃木笔下的吉卜力往事上来吧。本来只想摘一些只言片语，结果越摘越多，把书又看了一遍……\n铃木敏夫其人 本书的作者，也是吉卜力社长及多部动画的制作人。人称知道吉卜力秘密最多的男人、天才背后的策划师（驯兽师）。看完书有人感叹地总结到：一生操心的铃木君，一边要督促懒惰随性的的高畑老爷子，一边要哄傲娇的控制狂宫先生）。下面是一些书摘。\n不打寻常牌的铃木：\n我跟龟山商量说‘仅靠我们两个肯定不行，得找个人来当拉拉队长’，然后盯上了时任宣传部长的和田丰。他这个人喜欢赌博，我心想可以陪他玩一晚上骰子，两人各输5万日元，这样他就会为我们工作了。……当时在出版社工作的都是些无法适应社会的“混混”，而赌博是这类人的必修课……我发了疯的练习，也渐渐悟出了“输”的窍门。……反正现在时效已到，说出来也没关系了，电影《风之谷》诞生的契机就是那场赌博。\n我见宫崎骏哭成那样，只好去说服高畑。可他翻来覆去还是那句‘不想接’。无奈之下，我这辈子第一次也是最后一次抬高嗓门冲他吼道……大概很少有人敢这么吼他，这招立竿见影，他终于答应了我。一旦下定决心，高畑立刻变身成一位现实主义者，张口就问在哪里做。\n制作《哈尔的移动城堡》时，宫先生小脾气上来了，坚持不要搞多余的宣传，对此铃木的反应：\n被宫先生这么一说，我就想到了“无为而宣”的策略。……第一轮报导只用了城堡的素材，外加一句“这座城堡会动”的文案。没想到这样反而引起热议。此外，电影由于种种原因推迟，媒体的报道和猜测也为这部电影推波助澜。公布配音阵容的时候，更是引起轩然大波：木村拓哉的影响力真是不得了啊。\n善于从身边所有人汲取灵感的铃木：\n我从没看过他主演的电视剧，于是问女儿：木村的表演风格是怎样的？结果女儿只用一句话就解释清楚了：我觉得他能表现出男人那种不靠谱的感觉。我一听便想：找他给哈尔配音不是很合适吗！\n……“阿宫，你知道木村拓哉吗”“少瞧不起我，SMAP组合呗”“让他给哈尔配音怎么样”“啊？”于是我复述女儿的话，宫先生表示赞成：要的就是这个效果！\n高畑勋其人 高畑是细节狂魔，为了求证细节甚至亲自跑去种田，以及导出寻访小说或古籍中记载的事物，还会研究最新的制作技法。诸如此类的习惯总是导致项目严重滞后，当年《萤火虫之墓》一延再延，甚至到最后去菜园偷菜的重要场景以不上色的方式交付了……后来铃木想了一个“歪招”，在制作《平成狸合战》时，和发行方东宝联合起来一起骗高畑，计划上映时间是春天。果不其然，项目进度之后了，铃木看准时机说：事已至此，我就横下心跟东宝求情，想办法让他们改到夏天放映吧。……结果一算还是根本做不完，铃木试探道“干脆改到冬天？”高畑一反常态“呃，还是夏天吧”。铃木猜测：可能是高畑过意不去，也可能那时的高畑还残留着一丝严守制作计划的意识。对于这样风格的天才，铃木是这样想的：与高畑一起制作电影，虽然总会遇到各种困难，但在这个过程中我也学到了很多，真的很有意思。制作电影本身就好比一部纪录片，是一种知性的娱乐方式。\n现实主义的高畑：\n宫崎骏说：“时隔十年，能再次见到原彻，一起做点什么，也算是有缘了”这时高畑打断了他：“阿宫，别说这些无关紧要的废话了。作品又不是靠缘分做出来的，关缘分什么事呢。”那一刻，我深切地意识到，眼前这些人可不是什么半吊子。\n高畑用心力挺《龙猫》的企划：\n结果山下直言不讳地说：“《龙猫》这样的企划很难啊，观众还是想看《风之谷》《天空之城》这种片名中带外语单词的作品吧。” “山下副社长刚才所说，一定代表了宫崎骏影迷的意见。‘片名中带外语单词’这种表述还挺独特的，其实您想表达的是‘动作奇幻片’吧。观众的确想看这样的作品。”高畑继续说道，“可如果是这样，那要到何时才能拍上阿宫想做的《龙猫》那样的电影呢？”这话说得巧妙，山下副社长一听完就有点慌了……（但还只是答应做录像带而不是电影，于是铃木想到一个主意：如果只做一部《龙猫》不够，那就请高畑也做一部，两部同时推进不就行了吗？哈哈哈）\n……高畑对《龙猫》则是赞不绝口，说：“《龙猫》是我和阿宫这些年一起努力追求的东西的顶点。”而“这些年一起努力追求的东西”是什么呢？也许就是从普通人所遇到的平凡点滴、喜怒哀乐中挖掘出故事吧。\n《我的邻居山田君》票房惨淡，铃木在员工大会上背锅道歉：\n我横下心来，走上了讲台。“一切正如社长所说！”此时只见社长在台下一脸坏笑。我顿时火冒三丈：“失败的原因在于我们把发行公司从东宝换成了松竹……”\n我在员工大会上出了大丑，高畑却在庆功宴上当着大家的面发表了精彩的演讲。“就算这部电影没有火，我们也要以参与了它的制作为光荣！”这也太酷了吧。\n宫崎骏其人 完成《风之谷》后，宫崎骏宣布：我再也不做导演了，我不想再失去朋友了。……明明已经成为一名可以独立创作的导演，却想再做回“工作人员”，这也是宫崎骏不同于常人的地方。带领大家奋勇拼搏的确开心，然而当战斗结束，只剩下一副硝烟散尽、夕暮寂寥的光景时，留在心中的失落感让他渴望再次体验与大家一起创作的乐趣。\n负责作画的近藤喜文更是成了宫先生和高畑争夺的对象，但如果没有近藤，高畑确实没法开展，于是铃木说服了近藤加入了高畑的组，宫崎骏大为生气：\n“结果第二天早上八点左右，我接到了宫先生的电话。他突然说道：“我揍了阿近一顿。”这可把我吓坏了。细问之下才知道，他是在梦里揍的人。不过他也说：“气也消了，做就做吧。”这就是《龙猫》的起点。”\n总之宫先生是个很好的人。他重情重义，爱管闲事，明明自己很忙，却时时关注着《萤火虫之墓》的进度。据说他每天都会把那边的制作人员叫过来打听。回家后也是三句话不离《萤火虫之墓》，惹得他太太忍无可忍，责问道：“你成天把《萤火虫之墓》挂在嘴边，到底你在公司做什么啊？”这桩趣事也能体现出宫先生的为人。\n在《千与千寻》拿奖拿到手软后，最在意的却是一个小女孩的看法。小女孩一句看似的批评，却更让宫老开心：\n宫先生受不了一个人独占功劳，所以想尽可能的和他人分享，让自己轻松一点儿。……但是他从来没有因为这些事情浮躁过，电影观念也从未因此而动摇。……对我们来说，还有一件事比票房和奖项更重要。促使我们制作这部电影的千晶看完后会作何感想？首映会当天，宫先生格外紧张。……千晶是最后走出来的。宫先生战战兢兢的问：“怎么样？”千晶笑了笑：“真有意思”。这一句话，让宫先生和我们如释重负。\n……听说千晶回家后对父亲说：只有一个地方不太对。在电影最后的“完”时不是画了一只鞋子吗？那只鞋子画的不对。原来是有一次，千晶在木屋的河边玩耍时不小心把运动鞋掉进了河里，大家追着鞋子跑了一路。宫先生肯定是想起了那件事，所以才画了这幅画。千晶也是个很敏感的孩子，一看就意识到画的是那次的事情。只是鞋子的图案好像画错了。\n“应该是美少女战士的鞋子。”\n宫先生听说后，笑得可开心了。\n如何与宫崎骏这样特殊的天才打交道：\n还有一位“例外”是编剧丹羽圭子。在创作《借东西的小人阿莉埃蒂》的剧本时，宫先生也是想法日日变（好多编剧就是因为宫先生的这种习惯“壮烈牺牲”了），她却说：“这样能了解天才的思考过程啊，还有比这更有意思的吗！另一方面，《幽灵公主》和《千与千寻》的作画监督安藤雅司则非常享受和宫先生的激烈交锋。他会在和宫先生相抗衡的过程中追寻自己理想中的动画。美术专家男鹿和雄老师也有这样的倾向。要么积极接受并乐在其中，要么拿出匠人精神对抗到底——要和宫崎骏这位特殊的天才打交道，也许只有这两条路可走。\n和儿子宫崎吾郎的别扭相处：\n“我想让宫崎吾郎执导这部片子（《地海战记》）。”我一开口就遭到宫先生的激烈反对：“他怎么行啊，你疯了”反对的理由只有一条：他不擅长画画。……结果吾郎在分镜中展示出超出所有人预期的能力。 甚至在吉卜力之外，宫先生的 师傅大冢康生也惊叹到“虎父无犬子啊。” 庵野秀明也说:“这完全是宫崎骏的风格嘛!为什么不早点让他做啊?\n吾郎表现出的另一项能力是统率团队的领导力。这是连他父亲都不具备的天赋。宫崎骏是那种用过人的才华“统治”员工的导演……但工作人员难免会在这个过程中身心俱疲。而吾郎却用细心和体贴牢牢抓住了员工的心。作画工作启动后，他立刻理解了作画现场的金字塔形组织结构在精准掌控指挥系统的同时切实推进各项工作。如果动画师交上来的画出色，他不会音惜表扬，有问题时也会用明确易懂的话语下达指示。多亏了他，员工们都能以轻松愉快的心情投入工作，发挥出比平时更多的活力。另外，每逢周六他都亲自下厨犒劳大家。……虽然他没有多说，但我觉得他潜意识里终究想要赶超父亲。\n吾郎要是无法摆脱他对父亲的自卑情结，就不可能出人头地。为了他，那场戏（王子刺杀国王）也是必不可少的。后来有位心理学家和吾郎聊天，赞叹道：“我心想你有宫崎骏这样一位伟大的父亲，拍电影时肯定吃了不少苦头。结果跑去电影院一看，来就是弑父的场景，看得我格外激动。无论有没有缘由，父亲都是非‘杀’不可的。就因为他是父亲，所以才值得‘杀’。父亲越是伟大，越有‘杀’的价值。”对此吾郎如是回答道:“听到铃木说得让亚刃弑父，我觉得很有道理。倒不是说我非要超越父亲或必须冲破自己身上的束缚，只是结合当今年轻人的心境这是一种忍无可忍的感觉吧。\n……电影大功告成，放映结束后，宫先生自言自语道：即便还我来做，我也会做成这样。可作品的完成度确实让宫先生吃了一惊。但他却说道：“若要模仿，就不要让别人看出来你模仿的是谁！”\n当311大地震发生瞬间，宫老在做什么：\n《起风了》里面关于关东大地震的描写，我当时一直在琢磨地震的声音是什么样的呢?“3·11”大地震发生的时候，我在工作室里竖起耳朵听地震的声音，可怎么听都只有架子上的东西掉下来的声音，让我产生了“地震非常安静”的印象。\n高烟:听你这么一说，我就想起来了。当年遇到空袭的时候，总会有一段空白的时间和一段神奇的停顿。……\n对于工作这件事：\n“原来他不喜欢工作啊，这点我倒是完全可以理解……”\n不过人们的确会以工作的形式和社会接轨，获得精神世界的平静。失去“工作”这份属于自己的职责，对一个人来说是多么痛苦啊。\n关于创作 坚持与放弃\n接下来的一年，宫先生便窝在自己的工作室埋头绘制《画烟囱的小玲》……只见墙壁上贴满了Image Board，没人知道总共有多少张。可我没有多看这些画稿，只是说……（委婉的表达这个主打20岁年轻女性的动画企划不适合已经60岁的宫崎骏）……宫先生一边听我说，一边迅速起身，开始一张接一张地揭下墙上的Image Board。然后，他把画纸摞在一起，当着我的面咚一声扔进了垃圾桶。我至今都忘不了那一幕。“你的意思是这个项目行不通，对吧铃木？”我没有直说，但他一定读懂了我的神情。\n接着，他突然说道：“为千晶拍一部电影吧。”……（然后立即开始构思）……《小玲》遭到了我的反对，宫先生心里憋着一股气，于是发动了精彩的反击。他料定，只要搬出千晶和江户东京建筑园，我就绝对不会提出反对。他毫不犹豫地抛弃了酝酿了整整一年的项目，从零开始构思新的项目。并且，这一过程只花了五分钟。他的爽快和专注，真让我佩服得五体投地。这就是《千与千寻》的起源。\n使用套路还是冒险\n无脸男的提案的确有趣。只不过，会不会有小观众透过无脸男看到心灵的阴暗面呢？另一种方案便是联合小白达到钱婆婆，这么一来便是通俗易懂的奇幻动作大片。也许娱乐电影本该这么简单明了……“你定吧！”选打倒汤婆婆的……话都到嘴边了，可我最后还是下意识的说了“选无脸男”……说实话，我虽然担心，但认为能卖座的是“无脸男版”。早在制作《幽灵公主》的时候，我就观察到，单纯讲述惩恶扬善的故事已经吸引不了观众，娱乐电影也需要有哲学思想的时代已经到来了。\n回顾过去，日本电影的主题几乎都是贫穷与战胜贫穷。然而，经历了经济高速发展期，贫穷已经不足以成为主题了。之后又经历了泡沫经济的崩塌，很多人出现了心理问题。电影主题逐渐转变为心理问题与如何克服心理问题。《千与千寻》就诞生于这样的大环境下。\n对“俄狄浦斯情结”的现代意义的思考\n俄狄浦斯情结是一个很古典的主题，但我觉得它也能触动现代的观众。想当年，孩子们会在父母看不到的地方塑造只属于自己的世界，在那里学到各种各样的知识找到自我。\n但如今的孩子在被过度保护的环境中成长起来。换句话说，他们的举手投足都在父母的监视之下有时候，这种监视甚至会持续到他们成年。对孩子们来说，这是一个令人煎熬的时代。所谓的“寻找自我”之所以大行其道，出现心理问题的孩子之所以层出不穷，这恐怕就是背景原因之一。想要摆脱监视重获自由，想要找到自我——《地海战记》能够为这样的孩子指明前进的道路。\n对“社会变得浮躁和疯狂”的历史原因的思考\n时隔二十年，宫先生再次提出做《虞美人盛开的山坡》吧，他是这么想的：进入二十一世纪后，世界为什么变得越来越疯狂？经济的高速发展是不是使日本走向疯狂的催化剂呢？如果将故事设定在哪个时代，作品就有了审视现代社会的意义。\n……二十世纪六十年代的我还很年幼，但我记得那是一段非常光辉的岁月。……收入倍增计划这个词让我记忆犹新……另一件令我印象深刻的事情是，淫猥怪诞的东西从我们身边消失了，让人感觉“纯净的时代来临了”。学校里不存在霸凌现象，打架归打架，但从小学到高中我从没有看到过任何阴险的欺凌。身边的一切都是积极向上的，当然，负面消极的东西应该也是存在的，但人在埋头前进的时候是不会回头看过去的。于是我们就看不到任何令人不愉快的东西了。再加上在那个时代，全社会都很积极，很多问题也许就这样被掩盖住了吧。……可我们盼来的未来是怎么样的呢? 生活的确变得富足了，然而在这个物质泛滥的社会，很多人为自己该怎么生存而烦恼，出现了心理问题。这就是今天的日本。\n对“小朋友适合看什么样的东西”的思考\n《龙猫》也是如此，观影期间也有小朋友吓哭了。他们害怕的是龙猫本身。大约到了四五岁就能克服这种恐惧心理了。年纪更大一些的孩子则会迷上龙猫，一头栽进电影中的世界。 我认为这绝非巧合。当然，面向小朋友的电影最好能让人感觉被善良温暖的柔情所包裹着。然而世界上的确存在着可怕的东西，这些东西也必须被认真描写出来——宫先生正是怀着这样的意图创作的。《龙猫》这部作品的神髓便是在呈现温暖的同时也表现出恐惧。……这就是龙猫背负着的历史。它不仅是一种可爱的生物，也兼具骇人的元素。小朋友们会本能地感受到这一点。我和宫崎骏打了四十年的交道，深感他最大的特征就是童心未泯。他总能像孩童一样自由自在地发挥想象力，且想象出来的东西不总是光明的，也带有阴暗的一面。这也是他的魅力之一。\n对“年轻人的喜好”的思考\n我认为票房难创佳绩的原因除了影片的质量和宣传方式之外，还有一个更为本质的问题，那就是我察觉到社会已经开始逐渐转变了。说得再具体些，就是大家已经开始厌倦所谓的“寓言式电影”了，厌倦了用动画去描绘出一个奇幻的世界，再透过它来回顾现实世界。……反过来说，年轻人变得越来越强大，我们很难用这样的作品抓住他们的心，他们的目光更多地投向了现实。如今，这种倾向变得愈发明显，他们开始全盘否定上一辈人所做的一切了。当下的年轻人不想要电视剧中的“谎言”。换作以前，让人惊呼“什么”的意外转折是观众喜闻乐见的，然而时至今日，这种元素已经无法让他们感到惊讶了也许他们根本就不相信故事本身。他们只相信推动现实的原则，不相信流于幻想的原则。\n奇幻作品将走向何方? 我也不知道。不过，我们之所以制作《记忆中的玛妮》，是为了鼓励那些在现实世界中饱受折磨的人，为他们注入活下去的力量。也许我们并没有给出现实的解决方案。但我们可以陪伴你，告诉你“并非只有你一个人在受苦。”\n关于制作 因为各种原因需要对原来的想法删减时，如何考量？\n“诚如高畑所说，缩短结尾，可能会让观众认为电影想要表达的是老一套的“保护自然”。但高畑原来的方案也包括了“把保护自然挂在嘴边是不是也有问题”的疑问。这个世界没有那么简单，人类背负着更为复杂的使命活着——按他的思路制作，观众可以思考到这一深层。\n团队里有不合群的天才怎么处理？\n吉卜力有几位不太合群的动画师，技术水平自不必言，只是有的早上不来上班，有的特别任性，有的不听导演安排……把他们安排在作画现场可能会引发各种问题。我在工作室附近又租了一间房子，将“大侠”们专门养在那里。而且我明确规定，能入住的不限于员工，大侠们想带谁来就带谁。于是身怀绝技的无赖豪侠们反而纷至沓来。我们将那栋房子正式命名为“第四工作室”，专门用于处理需要优秀动画师完成的高难度工作。一方面，制作电影最讲究的就是团队合作；一方面，这些豪侠们一直都是吉卜力的中流砥柱，也毋庸置疑。\n写实还是抽象？\n高畑：在这次的《辉夜姬物语》中我们没有仔细描绘所有的空间和阴影，而是采用了带有速写色彩的手法，以此激发观众的想象力与记忆。看普通的动画时，观众会把自己看到的“画”当成是真的。可看速写画的时候，人会努力去想象“画图的人可能看到的对象本身”。\n关于发行 带有深意的作品刚完工时，是否要立即交给发行商讨论？\n不过我没有立刻通知东宝。因为我很清楚，如果在这个时候拿给他们，一定会引发各种关于内容的讨论。要是负面意见占了上风，说不定千辛万苦搭建起来的发行体系也会被彻底推翻。所以我告诉相关人员影片还没完成，连试映会都是拖到最后一刻才办。\n……果不其然，看完试映的相关人员的反应并不理想。“这部电影对孩子来说太难理解了。”还有人对宣传文案“活下去”提出质疑——情节已经很复杂了，还配上这种哲学味很浓的文案，不仅孩子提不起兴趣，女性观众、成年观众也不会买账的。\n但我打定主意宣传文案不作他想。因为我觉得，我们已经迎来了“电影也需要具备哲学内涵的时代”。我脑海中一直萦绕着从高畑那里听说的加里·库尔茨（《星球大战》的制片人）的观点。加里认为，以往好莱坞电影的首要主题是爱情。而《星球大战》的问世改写了历史，哲学也成了电影主题。”……既然如此，在宣传电影时提及哲学，也就是“生与死”的主体应该也是没问题的。……（还有各种容易引发争论的细节）……我早就料到会有人提出诸如此类的问题了。当然，只要认真看完这部电影，就会明白它绝不宣扬暴力，也没有涉及歧视。……肯定是因为我们做了很多前所未有的尝试，每个参与其中的人心里都没有把握。……为此，我们在各个城市展开了空前的宣传攻势……一部电影能否取得成功，绝不是听天由命的（酒香也怕巷子深），要尽的人事是在太多了。\n这样的合作方值得信赖吗？\n（和迪士尼谈合作时）别人都一个劲儿夸吉卜力的作品有多好，星野先生却只谈生意，态度又非常坦诚，这让我觉得他是值得信赖的人。经多方打听，我得知的是你有上百位销售专员，比其他公司强大得多。一九九六年，吉卜力和迪士尼正式签约，《幽灵公主》在全美上映一事也尘埃落定。\n如何确定宣传文案？\n（为《千与千寻》指定宣发主题时，很多工作人员都误以为主要讲的是千寻和小白的爱情故事）\n我决定掐表计算每个角色登场秒数……毫无疑问，第二名是无脸男。主推无脸男的方针对宣传文案也产生了影响……“你不是说过吗？‘好的文案往往诞生于偶然，并且大多数情况下都是最先说出来的那句话。但在反复锤炼中大家也许会忘记最初的表述。遇到这种情况，我们必须回归原点’。”市川建议用“唤醒活下去的力量”。……反响远超预期。广告行业就不用说了，“活下去的力量”甚至被应用在了教育和其他领域。\n脚注 在看《DOOM启示录》《Blood, Sweat, and Pixels》《硅谷传奇》时也有类似感受。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n这句台词出自《Legal High》第二季第七集。片中导演名叫宇都宫（和宫崎骏的故乡同名）。片中被气走的同事和差点崩溃的原告不难让人对应到细田守、押井守、宫崎吾朗和庵野秀明（原出处）……看完书会觉得，往往现实比电视剧还要精彩。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n即吉野源三郎的《你想活出怎样的人生》，出版于1937年，后面还会写文章展开说说。宫崎骏在小学时就在教科书上读过。“我至今还记得第一次读到《你想活出怎样的人生》时受到的冲击。”这也是宫崎骏老爷子将在一个月后上映的同名动画电影，据传是最后一部作品（希望不是）。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://pps43.github.io/posts/notes_on_genius_in_ghibli/","summary":"这本书带给我的，除了诸多耳熟能详的作品背后的逸闻趣事、诸位大师的才华风貌，还有不少对创作思路、团队协作、宣传发行的启发，相信能常看常新。同时","title":"吉卜力的天才们（铃木敏夫）"},{"content":" 当看到书名时，我承认内心有一丝挑战欲。受过系统的科研训练的人，往往对“真的”有“洁癖”。作者Robert Wright也认识到这一点，所以在开头便说，本书可以看作佛学观点的进化心理学解释。并不探讨轮回、神明这些超自然的部分，而探讨自然主义部分。并不探讨佛教各分支的细枝末节，而探讨核心思想。不要用佛教教义使自己成为更好的佛教徒，用它来做更好的自己。正是这句话让我有了继续读下去的意愿。\n进化心理学🐵 进化心理学研究的是大脑如何由自然选择设计来误导我们甚至奴役我们的。因为自然选择最终只关心有利于基因传播的基因特性。\n猴子实验表明，如果你尝试做一件事体验到一种新的快感，你会分泌大量多巴胺。但后续再次尝试做这件事，多巴胺分泌峰值会出现在你真正做之前。也就是说，期待的快感比实际体验的快感更强。作者将这种差异成为“幻觉”。\n幻觉的出现源自感觉。感觉最初的作用是趋利避害，是对所处环境中的事物做出评价：好还是坏。如果这种评价是准确的，就可以说某种感觉是真实的，否则称为幻觉。幻觉大致有两类：\n“环境错位”。自然选择是在特定的环境下设计出我们的感觉系统的，而如今外部人文环境突变，自然选择却没有及时更新设计而带来幻觉。例如，在原始部落以小规模、相对固定的族群为环境的生存规则下，自然进化让我们会特别在意他人怎么看待自己。但是在现代社会，一个人却能经常接触大量并不了解你的陌生人（尤其有了互联网以后），而保持别人眼中好印象的压力就会被放大。你可能急切想去确认对方对你的态度。也可能因为无法确认而痛苦或回避。 也叫“误报”，但往往关乎生死所以宁可误报不可漏报。 例如，我们至少身处于两种幻觉中，都属于上文提到的“环境错位”。我们以为自己对事物的掌控力比实际情况强；我们对自己的能力和品德的评价会明显偏离实际。自然选择设计出这两种幻觉，作用分别是帮助我说服外界世界我是始终如一的行为者值得信任；帮助我说服世界我应该得到赞扬而不是责备。\n总之，人类在自然选择的设计之下被植入一些幻觉而做一些特定的事情，比如吃饭、做爱、超越对手。现代社会也有大量的人为设计，利用同样的机制，似乎只要遵循三个原则：\n实现这些目标能带来某种快感。 但这种快感只能是短暂的。 调动动物性大脑更关注第一点而不是第二点。 作者认为进化心理学能够揭露真相，却并不能直接帮助人摆脱这种幻觉的控制。这也是作者从佛学、冥想中寻求切实对策的起因。\n佛教🙏 佛教分为小乘和大乘。内观禅修源自小乘佛教。大乘佛教中有一些关于幻觉的激进而广泛的理念，接近“唯心论”，即我们通过意识感知的事物实际上都是凭空的臆想。由此可以引申到佛学概念“空”。另一个佛学概念是“无我”，即所谓自我也是幻觉，并非真实的存在。本书大量篇幅都在探究这两种思想。\n正念冥想🧘‍♀️ “正念”和“正定”，都属于佛教中的“正道”。\n正定冥想通过专注于呼吸，使注意力集中。专注（入定）会带来宁静，如果持续足够长的时间，还会带来强烈的极乐和狂喜感。 正念冥想在注意力集中的基础上，用心体察自己的内心感觉，会让我们更好的体会美。和正念冥想相关的概念是“内观禅”。所谓内观，有三法印，用白话说就是三个标准： “诸行无常”（impermanence） “诸漏皆苦”（dukkha），苦在某些语境下指的是不满足。 “诸法无我”（notself/anatta），即自我是一种虚幻的错误的信念。 无我 说起“无我”，不得不提起《无我相经》中的佛陀梳理出的体验的五个种类，称为“五蕴”。\n色身。包括眼、耳这类感觉器官。 感觉。 辨识。可辨识的景象或声音。 心锁。复杂的情绪、思想等。 意识。特指对上述四点的认识。 接下来佛陀定义了所谓的“自我”，并试图证明其不存在。第一、所谓“自我”，应当具有一定程度的控制性。即如果存在“自我”，至少五蕴中有一蕴是受控的。然而我们并不能向其中任何一蕴发号施令，所以“自我”不存在。第二、所谓“自我”，应当具有一定程度的恒常性。即如果存在“自我”，至少五蕴中有一蕴具有历经岁月而不变的特质。然而稍加思辨就会发现五蕴都不是恒常的，所以“自我”不存在。\n对于非佛教徒，对于这种论证逻辑显然不太满意。而佛教徒对此更深的解读有会让人更加困惑。对此，作者的建议是从中汲取积极性的一面：\n不要想太多，去做。你有能力与自己的感觉、思想、冲动和辨识建立一种不同的关系，解决与其中几样的纠缠，从而实现某种程度的意识解放。 如果不再将这些我无法控制的感觉看作“自我”的组成部分，我就能从这些感觉中得到解脱。例如当五蕴之一受苦时，你的态度应该是：这不是我的，这不是我。 总之，关于佛陀对“自我”的真正理解的争论，是毫无意义的。但有一点启发：**我们对“自我”的概念有极大的误解。我们通常会将其与“控制”“恒常”联系在一起，但实际上会发现，自己收到的控制比想象中的少，身份也更具灵活性。**通过这个概念也许可以帮助一个人更好的冥想。\n现代心理学实验表明，可以通过控制实验对象的心理状态，改变其个人选择倾向。“感觉”决定了当下由哪个模块负责，决定你在那段时间里所做的事情、以及产生新的感觉。“意识”并没有自我控制权，大脑多个模块各自反应和相互作用塑造了我们的行为，意识最多是个众议院议长而不是总统。\n无相，不执于物 无相（The Formless）并不是说物质世界不存在，也不是否认物质世界有构架，而是指很多关于世间万物的意义都是我们后来强加上去的，比如价值观或某种体验，一旦强加了这种特别感，对其反应的强烈程度就会变高。\n人天生就有一种强烈倾向：归因事物的“本质”。这种倾向结合一些原始性的思考捷径，往往对本质和真相的解释造成偏差，常见的一种是错误归因：在评价某人的行为时会倾向于性格因素（即他是个怎样的人）而不是情境因素（他当时面对怎样的处境）。更进一步说明自然选择对人脑的影响。\n如果敌人或对手做了一件好事，我们倾向于将其归因为环境因素——他给乞丐钱只不过是为了取悦一位恰巧站在那里的女性；\n如果密友或盟友做了一件坏事，那么环境因素就会显得突出——他对要钱的乞丐大喊大叫是因为他工作压力太大。\n除非对我做了坏事，那么他将会被移出盟友这个分类。即使敌人对我做了好事，我依然对他心怀芥蒂。多么简单有效的生存法则啊。\n敌人的暴力行为归因于性格，因此可以进一步证明敌人天生好斗；敌人的亲善的行为归因于对情境的反应（某种技巧或是因弱势而做出的暂时性调整），因此也不需要对他们原本的形象做调整，因为敌人的本质是坏的。战争中，你最开始的想法是一个国家的领导人的本质是坏的。你会认为这个国家的本质是坏的——整个伊拉克或德国或日本。你转而又开始认为这个国家的所有士兵——甚至这个国家的所有人——本质都是坏的。这些人是坏人，那就么你杀了他们也不用遭受良心的谴责！\n谁让他们本质是坏的呢……\n佛教中的不执于物，并不是引导人变成一个毫无情感、没有情绪波动的机器人。作者认为，持续佛学修行，可以丰富情绪，使人的情感变得更敏锐，使人变得更幸福喜乐，对待世界的方式可以更自由（换言之，不给事物归因太强的本质，正是自由的源头）。比如，让父母之爱变得没有那么强的占有欲。或许这样一来父母不再那么焦虑，控制欲也有舒缓，结果父母和孩子都会变得更幸福。\n开悟，无源之见 开悟，真的是得到终极真理了吗？\n开悟，究竟是怎样一种体验？\n有人认为，佛教的开悟之路就是对自然选择下的人脑的反抗。有人认为是体验到无我。有人认为，开悟就是看到万物的无常、克服贪爱等枷锁。\n还有一种理解叫“无源之见”（The View From Nowhere）：不带任何自私偏见的洞察，而且在一定程度上甚至根本不是任何特定人类的视角，或是其他物种的视角，即任何个体的利益并不比其他任何个体的利益更重要。自然选择机制创造了许许多多不同的视角，而佛教的开悟就是要超越所有这些视角、抵制自我特殊性这种核心的进化价值观——这种价值观造成的扭曲力场所产生的敌意已经深深影响了人类社会：种族问题、宗教问题、国家问题和意识形态冲突等。\n靠冥想拯救世界看起来难免太过天真幼稚，作者想强调的是，通过培养冷静清明的大脑，才能在面对威胁时不至于反应过度、恶性循环。我们不需要去爱敌人，但想要清醒地认识敌人，就要抑制恐惧和嫌恶，还要超越更微妙的感知和认知扭曲。\n所以佛学为什么是真的？ 作者说，佛学为什么是真的？因为我们是自然选择造就的动物。关于自然选择植入我们头脑中哪些倾向性，早期佛学思想家在科学资源有限的条件下，做出来了不起的评价。如今，根据对生物学和脑科学的现代研究，我们可以为这些评价提供新的支持。\n其实看到这里，我也并不在意真假之辩了，这本书已经带给我一些新的有益的思考，便已足够。\n后记 在讨论“无我”的时候写到，心理学研究和佛学思想中对人脑决策的模块化建模方式，可以为游戏AI尤其是拟人化AI行为提供启发。即预先设计模块化的专门系统，然后设计多种情绪触发器，每种触发器可以触发不同组合的专门系统。曾有心理学家给出粗糙的7个模块：自我保护、吸引配偶、保住配偶、友好关系、关爱亲属、社会地位、预防疾病。\n最后，本文使用了诸多佛教用语，并不一定是“正统解读”，所以希望佛教中人莫要见怪。一定要说的话，大概算是窥见一丝精神内涵后赋予的现代社会和心理的一种理解。话又说回来，什么又是正统呢。\n","permalink":"https://pps43.github.io/posts/notes_on_why_buddhism_is_true/","summary":"当看到书名时，我承认内心有一丝挑战欲。受过系统的科研训练的人，往往对“真的”有“洁癖”。作者Robert Wright也认识到这一点，所以在开","title":"洞见·为什么佛学是真的"},{"content":" PhysX物理引擎 这个系列主要记录一些最近在游戏开发中学习和使用Nvdia PhysX 3.4物理引擎的一些经验。 本文主要介绍场景查询的一些内部机制和使用方法。\nWarm up 官方资料：\nPhysX 3.4 source code Download PhysXGuide.chm A Scene in PhysX engine is a container of objects in a hierachical manner.\n--- title: Scene Hierachy --- classDiagram direction LR class world class scene { Flags Gravity ... } class actor { ActorFlags Name GlobalPose ... } class shape { Flags GeometryType LocalPose ... } class geometry { halfExtents for box ... } class material { friction restitution damping } world \u0026#34;1\u0026#34;*.. \u0026#34;N\u0026#34;scene scene \u0026#34;1\u0026#34;*.. \u0026#34;N\u0026#34;actor actor \u0026#34;1\u0026#34;*.. \u0026#34;N\u0026#34;shape shape o--geometry shape o--material There are only position and rotation in GlobalPose and LocalPose, no \u0026ldquo;scale\u0026rdquo;. Scale only reflects on geometry\u0026rsquo;s actual size.\nScene Query Basics Three kinds of scene query:\nraycast sweep overlap In general, each SceneQuery traverses a culling structure containing the scene objects, performs a precise test using the GeometryQuery functions, and accumulates the results.\nYou can customize filtering logic via prefilter and postfilter.\nflowchart LR BP(Broad Phase) --\u0026gt; prefilter --\u0026gt; MP(Mid phase) --\u0026gt; NP(Narrow Phase) --\u0026gt; postfilter Broad phase traverses the global scene spatial partitioning structure to find the candidates for mid and narrow phases. midphase traverses the triangle mesh and heightfield internal culling structures, to find a smaller subset of the triangles in a mesh reported by the broad phase. Narrow phase performs exact intersection tests Pre-filtering happens before midphase and narrow phase and allows shapes to be efficiently discarded before the potentially expensive exact collision test. Post-filtering happens after the narrow phase test and can therefore use the results of the test (such as PxRaycastHit.position) to determine whether a hit should be discarded or not. More on Traversal A scene uses two query structures, one for \u0026ldquo;static\u0026rdquo; objects (PxRigidStatic), one for \u0026ldquo;dynamic\u0026rdquo; objects (PxRigidBody). Each structure can use different culling algorithms, see PxPruningStructureType.\nPxPruningStructureType Explaination eNone Based on grid. Full rebuild when changed. eDYNAMIC_AABB_TREE Based on tree. Full rebuild when changed. Only choose this if all static actors in your scene are not modified after initialization. eSTATIC_AABB_TREE Based on grid and tree. Incremental rebuild when changed, unless by force. Choose this if frequently add/remove geometry, at the cost of higher memory More on Filtering To make custom filtering logic works, there are 3 steps.\nAttach data for filtering on the shape Attach PxFilterData to each shape. It has four 32bit words to hold custom data, e.g., we use word0 as layer of this shape. Here is an example:\nPxShape* shape = PxRigidActorExt::createExclusiveShape(*pxActor, PxBoxGeometry(extV), *pxMaterial); PxFilterData queryFilter; queryFilter.word0 = layer; shape-\u0026gt;setQueryFilterData(queryFilter); Define custom filtering logic Define callback function for prefilter and postfilter. See PxQueryFilterCallback. The logic is totally depend on yourself, just return PxQueryHitType to tell if this shape can pass.\nPxQueryHitType Explanation eNONE Shall not pass. eTOUCH Pass, but does not stop the raycast or sweep. eBLOCK Pass, but stop here. Here is an example:\nclass PhysxQueryFilterCallback : public PxQueryFilterCallback { public: PhysxQueryFilterCallback(); PhysxQueryFilterCallback(bool isBlocking, bool includeTrigger); virtual PxQueryHitType::Enum preFilter(const PxFilterData\u0026amp; filterData, const PxShape* shape, const PxRigidActor* actor, PxHitFlags\u0026amp; queryFlags); virtual PxQueryHitType::Enum postFilter(const PxFilterData\u0026amp; filterData, const PxQueryHit\u0026amp; hit); private: PxQueryHitType::Enum m_HitType; bool m_IncludeTrigger; }; PxQueryHitType::Enum PhysxQueryFilterCallback::preFilter(const PxFilterData\u0026amp; filterData, const PxShape* shape, const PxRigidActor* actor, PxHitFlags\u0026amp; queryFlags) { bool isTrigger = shape-\u0026gt;getFlags() \u0026amp; physx::PxShapeFlag::eTRIGGER_SHAPE; if (isTrigger \u0026amp;\u0026amp; !m_IncludeTrigger) { return PxQueryHitType::eNONE; } PxFilterData shapefilterData = shape-\u0026gt;getQueryFilterData(); if (shapefilterData.word0 \u0026amp; filterData.word0 || shapefilterData.word1 \u0026amp; filterData.word1) { return m_HitType; } return PxQueryHitType::eNONE; } PxQueryHitType::Enum PhysxQueryFilterCallback::postFilter(const PxFilterData\u0026amp; filterData, const PxQueryHit\u0026amp; hit) { const PxLocationHit\u0026amp; impactHit = static_cast\u0026lt;const PxLocationHit\u0026amp;\u0026gt;(hit); if (impactHit.distance \u0026gt; 0.0f) return m_HitType; return PxQueryHitType::eNONE; } Attach filter in your scene query PxQueryFilterData has two fields:\nfield Explaination PxQueryFlags Supported flags are in PxQueryFlag::Enums, e.g. raise ePREFILTER means all shapes need to pass prefilter you defined. PxFilterData Has four 32bit words for you, e.g. use word0 as the \u0026ldquo;layermask\u0026rdquo; of the query. Raycast example Here is an example of raycast (return multiple objects).\n// save result and use it later struct MyRaycastHitResult { PhysXVec3 Position; PhysXVec3 Normal; float Distance; PhysXActor* Collider; }; typedef PhysXArray\u0026lt;MyRaycastHitResult\u0026gt; MyRaycastHitResults; // make sure \u0026#34;direction\u0026#34; is non-zero and normalized! bool MyRaycast(MyRaycastHitResults\u0026amp; hitResults, const PhysXVec3\u0026amp; startPos, const PhysXVec3\u0026amp; direction, float distance, unsigned int layerMask, bool includeTrigger) { const PxU32 bufferSize = 256; PxRaycastHit hitBuffer[bufferSize]; PxRaycastBuffer buf(hitBuffer, bufferSize); PxQueryFilterData filterData = PxQueryFilterData(); filterData.flags |= PxQueryFlag::ePREFILTER | PxQueryFlag::ePOSTFILTER; // will call both prefilter and post filter filterData.data.word0 = 0; filterData.data.word1 = layerMask; PhysxQueryFilterCallback filterCallback(false, includeTrigger); bool status = m_pxScene-\u0026gt;raycast(startPos, direction, distance, buf, PxHitFlag::eDEFAULT, filterData, \u0026amp;filterCallback, NULL); if (status) { hitResults.clear(); for (PxU32 i = 0; i \u0026lt; buf.nbTouches; i++) { PxRaycastHit touch = buf.touches[i]; MyRaycastHitResult hitResult; hitResult.Position = touch.position; hitResult.Normal = touch.normal; hitResult.Distance = touch.distance; hitResult.Collider = (PhysXActor*)touch.actor-\u0026gt;userData; hitResults.push_back(hitResult); } if (buf.hasBlock) { MyRaycastHitResult hitResult; hitResult.Position = buf.block.position; hitResult.Normal = buf.block.normal; hitResult.Distance = buf.block.distance; hitResult.Collider = (PhysXActor*)buf.block.actor-\u0026gt;userData; hitResults.push_back(hitResult); } } return status; } Overlap example Here is an example of sphere overlap. Other geometries are similar.\n// make sure radius is above zero! bool PhysXManager::MySphereOverlap(PhysXRaycastHits\u0026amp; hitResults, float radius, const PhysXVec3\u0026amp; position, const PhysXQuat\u0026amp; rotation, unsigned int layerMask, bool includeTrigger) { const PxU32 bufferSize = 256; PxOverlapHit hitBuffer[bufferSize]; PxOverlapBuffer buf(hitBuffer, bufferSize); PxQueryFilterData filterData = PxQueryFilterData(); filterData.flags |= PxQueryFlag::ePREFILTER;// no postfilter logic since we SHOULD NOT EXAMINE DISTANCE in overlap query filterData.data.word0 = 0; filterData.data.word1 = layerMask; PhysxQueryFilterCallback filterCallback(false, includeTrigger); bool status = false; PxTransform trans(position, rotation); status = m_pxScene-\u0026gt;overlap(PxSphereGeometry(radius), trans, buf, filterData, \u0026amp;filterCallback); if (status \u0026amp;\u0026amp; buf.nbTouches \u0026gt; 0) { hitResults.clear(); for (PxU32 i = 0; i \u0026lt; buf.nbTouches; i++) { PxOverlapHit hit = buf.touches[i]; PhysXRaycastHit hitResult; hitResult.Collider = (PhysXActor*)hit.actor-\u0026gt;userData; hitResults.push_back(hitResult); } } return status; } Golden Tips Make sure shape dimension and queryshape dimension have positive values, recommended minimum value is 1.192092896e-07F. Or random crash may happen. In Raycast or Sweep, make sure direction is normalized and not zero. Or random crash may happen. In Overlap, do not check `hit.distance`` (it\u0026rsquo;s always zero) in post-filtering logic. ","permalink":"https://pps43.github.io/posts/using_physx_scenequery/","summary":"PhysX物理引擎 这个系列主要记录一些最近在游戏开发中学习和使用Nvdia PhysX 3.4物理引擎的一些经验。 本文主要介绍场景查询的一些内部机制和使","title":"PhysX物理引擎: Scene Query"},{"content":"上一篇我们聊了AI模型的分类和大致架构，目前最火的两类模型LLM和Diffusion都基于Transformer架构训练而成，ChatGPT则是LLM家族中最出色的产品。本文就来聊聊最近出现的基于ChatGPT的创新架构和应用。由于ChatGPT的训练数据截止到2021年9月，且笔者并没有Plus会员才能使用的ChatGPT Plugin，所以这次请到的是Dr. Phind（The AI search engine for developers），大家欢迎。\n系列文章\n跟AI老师学AI（一） 跟AI老师学AI（二） 课堂问答 Auto-GPT Me:\nwhat is autogpt and how does it work\nDr. Phind:\nAuto-GPT is an experimental open-source project built on the latest ChatGPT model i.e GPT-4. It is a variant of ChatGPT developed by Significant Gravitas and it uses the ChatGPT API to work. Specifically, Auto-GPT utilizes the GPT-4 API, though it seems like it should work with the GPT-3.5 API as well. Auto-GPT is an AI that does the work for you by setting a goal and then generating and completing tasks. It does all the follow-up work for you, asking and answering its own prompts. It automates multi-step projects that would have required back-and-forth prompting if you worked directly with GPT-4. In other words, it \u0026ldquo;chains together LLM \u0026rsquo;thoughts\u0026rsquo;, to autonomously achieve whatever goal you set.\u0026rdquo;\nThere are new apps that have emerged to make Auto-GPT even easier to use, like AgentGPT and GodMode, which provide a simple interface where users can input what they want to accomplish directly on a browser page.\nMe:\nhow does AutoGPT work exactly? Find the techniques behind.\nDr. Phind:\nAuto-GPT is a Python application built on top of GPT-4 that allows the AI to function independently without requiring prompts from the user for each action.\nAuto-GPT breaks down the AI’s actions into “thoughts,” “reasoning,” and “criticism,” which enables users to understand precisely what the AI is doing and why it’s doing it.\nAuto-GPT uses long and short-term memory management, which is similar to how humans learn from their mistakes. Auto-GPT has the ability to assess its work, improve upon past experiences, and leverage its history to generate more precise results. Auto-GPT\u0026rsquo;s integration with vector databases, a memory storage solution, allows it to retain context and make informed decisions.\nMe:\nlist some autonomous agent besides autogpt\nDr. Phind:\nhere are several other autonomous AI agents besides Auto-GPT, some of which are Camel, BabyAGI, and Westworld simulation.\nCamel is an autonomous AI agent that uses LangChain to store and retrieve information. It can learn and understand human language and is capable of making decisions based on the context. Camel can generate content for social media and can perform simple tasks like booking a restaurant reservation or scheduling a meeting (Reference).\nWestworld simulation is an autonomous AI agent that simulates the Westworld environment. It uses reinforcement learning to improve its decision-making ability and can learn from its mistakes. Westworld simulation can interact with other agents in the environment and can perform tasks like navigating through the environment, recognizing objects, and even interacting with human.\n⚡Me: In fact it\u0026rsquo;s an interactive sandbox environment created by researchers from Stanford and Google, the paper is here (PDF) and this is the basic architecture. BabyAGI is another autonomous AI agent that uses GPT-4, Pinecone, LangChain, and Chrome to generate and execute tasks. It can make human-like cognitive decisions and can write and run codes to meet certain objectives. BabyAGI can retain long-term memory of tasks and events with the help of Pinecone and LangChain, making fetching information faster. Its decisiveness makes it an effective tool for cryptocurrency trading, robotics, and autonomous driving.\n⚡Me: add info from Github: the script works by running an infinite loop that does the following steps: These autonomous AI agents have different capabilities and approaches to accomplishing tasks. Camel is useful for generating content for social media and performing simple tasks, Westworld simulation is useful for simulating environments and interacting with other agents and BabyAGI is useful for decision-making sectors like autonomous driving and robotics.\nBabyAGI Me:\nwhat is babyagi and compare with autogpt?\nDr. Phind:\nBabyAGI and Auto-GPT are autonomous AI agents designed to generate and perform tasks based on a given objective. The primary difference between the two is the way they approach the objective, the techniques they use, and their purpose.\nBabyAGI uses a combination of GPT-4, Pinecone, LangChain, and Chrome to create and execute tasks. It creates a task list based on the objective entered and executes them one by one. The results of one task determine the next one. It can retain a long-term memory of tasks and events with the help of Pinecone and LangChain, which makes fetching information faster. Since it uses a trial-and-error basis to decode the results of previous tasks, BabyAGI can make complex decisions without losing track of the predefined objective.\nAuto-GPT, on the other hand, generates and runs multiple tasks at once using GPT-4 and creates an artificial memory space using GPT-3.5 to store results from previous tasks. It has access to internet services like apps, websites, books, documents, and articles and can use them to complete tasks required to reach the objective. Auto-GPT is good at generating text-rich content and images. It can also provide human-like text responses, making it useful for generating content, summarizing texts, and translating text into more than a dozen languages\nVector Database Me:\nwhat is vector database and how does it integrate into above system?\nDr. Phind:\nVector database is a type of database that is designed to handle high-dimensional data such as embeddings, which are numerical representations of objects or concepts in a high-dimensional space. In the context of Auto-GPT, vector databases are used to store the embeddings of documents that are generated by OpenAI\u0026rsquo;s language model. The vector database is used to enable similarity search over these embeddings, which is used by Auto-GPT to find the most relevant documents to complete a task.\n(Me: Below is just one example to integrate pgvector to auto-gpt, there are other choice, e.g., weaviate)\nThe vector database is integrated into the Postgres database using pgvector, an open-source vector similarity search extension for Postgres. In more detail, open-source vector similarity search extension pgvector allows for storing and querying vector embeddings in a Postgres database. OpenAI\u0026rsquo;s text-embedding-ada-002 model outputs 1536 dimensions, so that is the size of the vector used in Auto-GPT. The pgvector extension introduces a new data type called vector, which is used to create a column named embedding with the vector data type in the Postgres database. The similarity search over these embeddings is performed using a function named match_documents, which takes a query embedding, a match threshold, and a match count as inputs and returns a table of document IDs, content, and similarity. The similarity is calculated using vector math operations like cosine distance. (Reference)\nMe:\nlist some popular vector database product or repo\n(Dr.Phind\u0026hellip;. Google and Google Bard comes to help):\nSure, here are some popular vector database products or repos:\nFAISS (Facebook AI Similarity Search) is a library for efficient similarity search of dense vectors. It is open source and available on GitHub. Milvus: Milvus is a vector database designed for high-performance similarity search and machine learning.Milvus 2.0 is a cloud-native vector database with storage and computation separated by design. All components in this refactored version of Milvus are stateless to enhance elasticity and flexibility. Annoy (Approximate Nearest Neighbors Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are mmapped into memory so that many processes may share the same data. weaviate These are just a few of the many vector database products and repos that are available. The best product or repo for you will depend on your specific needs and requirements.\nLangChain Me:\nwhat is langchain and how does it work?\nDr. Phind:\nLangChain is a Python package that provides a standard interface for chains, integrations with other tools, and end-to-end chains for common applications [3]. It is designed to assist in four main areas, which are listed here in increasing order of complexity: prompts, long-term memory (LLMs), tools, chains, agents, and memory [2].\nLangChain is a framework for developing applications powered by language models. It is created to be data-aware and agentic, meaning that it connects a language model to other sources of data and allows a language model to interact with its environment.\n(\u0026hellip;) LangChain can be used in a variety of ways, including autonomous agents, personal assistants, question answering, chatbots, querying tabular data, code understanding, interacting with APIs, summarization, and evaluation.\nMe:\ndoes AutoGPT use Langchain?\nDr. Phind:\nThere is no mention of AutoGPT using LangChain in the provided context. While LangChain is a framework that makes it easier to build scalable AI/LLM apps and chatbots, there is no clear indication that AutoGPT specifically uses LangChain.\n课后笔记 Autonomous agents (e.g., AutoGPT, BabyAGI) can auto-create tasks towards the GOAL you give them, and auto-find the way to complete task based on GPT models and other data sources (websites, your documents, etc), and even auto-improve themselves from previous mistakes. The basic structure is somehow similar to GOAP in video game\u0026rsquo;s AI design. They can achieve these because they can have long-term and short-term memory powered by Vector Database. ( memory size is much more than single GPT4\u0026rsquo;s context which is 32K tokens, ~24K words.) Vector Database is a specialized db to handle vectors (read, write, calculate similarities, etc). they are useful for text because text can be transformed into numberic vectors by embedding technique. Similarity between embeddings (vectors) reflect relevance between text. Hence above agents can retrieve relevant data from large datasource and sending to GPT as context. Frameworks like LangChain makes it easier to implement autonomous agents because it provides a standard interface to handle different tools and data sources. 拓展阅读\nTutorial: ChatGPT Over Your Data (using LangChain) Create your own chat bot with GPT-Index \u0026amp; LangChain ","permalink":"https://pps43.github.io/posts/asking_ai_about_ai_2/","summary":"上一篇我们聊了AI模型的分类和大致架构，目前最火的两类模型LLM和Diffusion都基于Transformer架构训练而成，ChatGPT","title":"跟AI老师学AI（二）"},{"content":"按照目前AI在学术界、工业界推陈出新的速度，感兴趣的同学们纷纷表示：真的学不动啦！不要慌，AI老师来了~ 在本系列中，我不会提前学习预备知识，以门外汉的视角去追问AI并了解一些基本概念。既可以锻炼提问技巧，还可以在听完高屋建瓴的讲解后有针对性的去学习感兴趣的部分，效率倍增！\n系列文章\n跟AI老师学AI（一） 跟AI老师学AI（二） 课堂问答 Generative Models, Transformers, Large Language Models (LLM) ? Me:\nexplain generative models and list some types of it. And explain the relationship and differences with LLM.\nChatGPT:\nGenerative models are a type of machine learning model that learns to generate new data that is similar to the training data it was trained on. Unlike discriminative models, which learn to classify input data into specific categories, generative models focus on learning the underlying patterns and structure of the input data, allowing them to generate new data that is similar to the input data.\nThere are several types of generative models, including:\nVariational Autoencoders (VAEs) Generative Adversarial Networks (GANs) Autoregressive models, such as PixelCNN and PixelRNN Boltzmann Machines Restricted Boltzmann Machines (RBMs) Deep Belief Networks (DBNs) Language Models (LMs) are a type of generative model that specifically focuses on generating natural language. Like other generative models, LMs are trained on a large corpus of text data and learn to generate new text that is similar to the input data. However, LMs differ from other types of generative models in that they specifically focus on generating text and incorporate language-specific features, such as grammar, syntax, and vocabulary.\nOne key difference between LMs and other types of generative models is that LMs are typically based on probabilistic models, such as n-gram models or neural network models, whereas other types of generative models, such as GANs and VAEs, are typically based on deep learning architectures. Additionally, LMs may incorporate language-specific constraints, such as word order and grammar, that are not present in other types of generative models.\nMe:\nDo you mean generative models are unsupervised learning, while discriminative models are supervised learning?\nChatGPT:\nGenerative models can be trained using both supervised and unsupervised learning approaches, depending on the specific task and the type of data being used. In unsupervised learning, the model is trained on a dataset without explicit labels, and the goal is to learn the underlying structure and patterns in the data. In supervised learning, the model is trained using labeled data, and the goal is to learn to predict the label of new, unseen data.\nHowever, it is true that discriminative models are typically used for supervised learning tasks, such as classification, regression, and sequence labeling. These models learn to map input data to specific output labels or categories. In contrast, generative models are more commonly used for unsupervised learning tasks, such as density estimation, data synthesis, and anomaly detection. These models learn to generate new data that is similar to the training data, without necessarily mapping input data to specific output labels or categories.\nMe:\nGot it. Now explain what transformers is about in deep learning, and the relationship between generative models and the transformers.\nChatGPT:\nTransformers are a type of deep learning model that has become increasingly popular in natural language processing (NLP) tasks, such as language modeling, machine translation, and sentiment analysis. The Transformer architecture was introduced in a 2017 paper titled \u0026ldquo;Attention Is All You Need\u0026rdquo; by Vaswani et al., and it has since become the foundation for many state-of-the-art NLP models.\nThe key innovation of the Transformer architecture is the use of self-attention mechanisms to replace traditional recurrent or convolutional neural networks. Self-attention allows the model to weigh the importance of different parts of the input sequence when generating each output token. This enables the model to capture long-range dependencies and context more effectively, resulting in better performance on many NLP tasks.\nGenerative models, such as language models, can be built using the Transformer architecture. In fact, many of the most successful language models, such as OpenAI\u0026rsquo;s GPT series and Google\u0026rsquo;s BERT, are based on the Transformer architecture. These models are trained on large amounts of text data using unsupervised learning techniques, such as autoregressive language modeling or masked language modeling. Once trained, the models can be used to generate new text that is similar to the training data, or to perform downstream NLP tasks, such as sentiment analysis or machine translation.\nIn summary, the Transformer architecture is a powerful tool for building deep learning models for NLP tasks, including generative models such as language models. By leveraging self-attention mechanisms, Transformers are able to capture long-range dependencies and context more effectively, resulting in better performance on many NLP tasks.\nModels, Architectures? Me:\nDo you mean one model can be implemented in different architectures, and transformers are just one of the architectures to build models? If this is true, list some other architectures popular.\nChatGPT:\nYes, that\u0026rsquo;s correct. A single machine learning or deep learning model can be implemented using different architectures, depending on the specific task and the type of data being used. The choice of architecture can have a significant impact on the performance and efficiency of the model.\nIn addition to the Transformer architecture, there are several other popular deep learning architectures for building models in various domains. Here are a few examples:\nConvolutional Neural Networks (CNNs): These are commonly used in computer vision tasks, such as image classification, object detection, and segmentation. Recurrent Neural Networks (RNNs): These are often used for sequence modeling tasks, such as natural language processing, speech recognition, and time-series prediction. Long Short-Term Memory Networks (LSTMs): These are a type of RNN that are designed to handle long-term dependencies in sequences. Autoencoders: These are used for unsupervised learning tasks, such as feature extraction, data compression, and anomaly detection. Generative Adversarial Networks (GANs): These are used for generative modeling tasks, such as image synthesis, data augmentation, and video prediction. Variational Autoencoders (VAEs): These are also used for generative modeling tasks, such as image synthesis and data generation, but they incorporate probabilistic models and encode latent variables. These are just a few examples of the many deep learning architectures that are available for building models. The choice of architecture will depend on the specific task and the characteristics of the data being used.\nDiffusion, Stable Diffusion, latent space? Me:\nExplain stable diffusion to me. Is it a model, architecture, or others?\nChatGPT:\nStable Diffusion is a probabilistic model for generative modeling and data synthesis, and it is related to the concept of Generative Diffusion Models (GDMs).\nAt a high level, the Stable Diffusion model uses an iterative diffusion process to model the distribution of the data. The diffusion process involves iteratively adding noise to the input data and then progressively filtering out the noise using a series of conditional distributions. This process results in a sequence of probability distributions, each of which approximates the true data distribution more closely than the previous one.\nUnlike traditional diffusion models, which can suffer from instability due to the accumulation of noise over time, the Stable Diffusion model incorporates a stability regularization term to prevent this from happening. This regularization term encourages the diffusion process to converge to a stable distribution, resulting in more accurate and reliable generative models.\nThe Stable Diffusion model is closely related to Generative Diffusion Models (GDMs), which also use a diffusion process to model the data distribution. However, GDMs suffer from instability due to the accumulation of noise over time, and they require careful tuning of the learning rate to avoid this. The Stable Diffusion model addresses this issue by incorporating a stability regularization term, which improves the stability and reliability of the model.\nIn summary, Stable Diffusion is a probabilistic model for generative modeling and data synthesis that uses an iterative diffusion process and a stability regularization term to improve the stability and reliability of the model. It is closely related to Generative Diffusion Models (GDMs) but incorporates additional features to address the instability issues that can arise in traditional diffusion models.\nMe:\nDo you know stable diffusion 2? It\u0026rsquo;s said to be a latent diffusion model, what does it mean?\nChatGPT:\nYes, Stable Diffusion 2 is a follow-up work to the original Stable Diffusion model and is a latent diffusion model.\nA latent diffusion model is a type of generative model that learns a low-dimensional representation (or latent space) of the data that captures the underlying structure of the data. In other words, instead of modeling the data directly, the model learns to generate the data by sampling from a distribution in the latent space and then mapping the samples back to the data space.\nStable Diffusion 2 extends the original Stable Diffusion model by introducing a latent diffusion process. The model learns a diffusion process in the latent space, which allows it to generate data that has a more complex and structured distribution than the original model. The latent diffusion process involves iteratively adding noise to the latent space and then filtering out the noise using a series of conditional distributions. This process results in a sequence of probability distributions in the latent space, each of which approximates the true data distribution more closely than the previous one.\nOnce the model has learned the diffusion process in the latent space, it can generate new data by sampling from the final distribution in the latent space and then mapping the samples back to the data space. By using a latent diffusion process, Stable Diffusion 2 is able to generate data that has a more complex and structured distribution than the original model, making it suitable for more challenging generative modeling tasks.\nIn summary, Stable Diffusion 2 is a latent diffusion model that learns a diffusion process in the latent space to generate complex and structured data distributions. It is a more advanced version of the original Stable Diffusion model and is suitable for more challenging generative modeling tasks.\nMe:\nexplain latent space like I\u0026rsquo;m 5\nChatGPT: 👍\nImagine you have a big box full of toys. Each toy has different colors, shapes, and sizes. Now, imagine you have a secret map that tells you how to mix and match the toys to create new toys that no one has ever seen before. This secret map is like a code, and it\u0026rsquo;s hidden inside the box.\nThe box of toys is like the data, and the secret map is like the latent space. The latent space is a hidden space that tells you how to mix and match the different parts of the data to create something new. It\u0026rsquo;s like a secret code that only the computer knows.\nWhen you train a model to learn the latent space, it\u0026rsquo;s like teaching the computer to find the secret map inside the box of toys. Once the computer knows the secret map, it can create new toys that no one has ever seen before by mixing and matching the parts of the toys in new and interesting ways.\nSummarize the talk Me:\nSummarize our conversation above to give a thorough and concise relationship among all the models, architectures, and other important concepts we talked about.\nChatGPT:\nIn summary, we discussed several important concepts in deep learning, including generative models, discriminative models, language models, and architectures such as Transformers and Generative Adversarial Networks (GANs).\nGenerative models are used for unsupervised learning and aim to model the data distribution to generate new data. Discriminative models, on the other hand, are used for supervised learning and aim to learn the decision boundary between different classes.\nLanguage models are a type of generative model that learns to predict the probability of a sequence of words, given some context. Transformers are a popular architecture used for language modeling, which use a self-attention mechanism to capture long-range dependencies in the input.\nGenerative Adversarial Networks (GANs) are a type of generative model that uses two neural networks, a generator and a discriminator, to generate new data that is similar to the training data. The generator tries to create new data that can fool the discriminator, while the discriminator tries to distinguish between the generated data and the real data.\nFinally, we discussed Stable Diffusion and Stable Diffusion 2, which are probabilistic generative models that use a diffusion process to model the data distribution. Stable Diffusion 2 is a latent diffusion model that learns a diffusion process in the latent space to generate complex and structured data distributions. The latent space is a hidden space that tells the model how to mix and match the different parts of the data to create something new.\n课后笔记 We train a model by choosing an architecture. Some models are named after the architecture they use, e.g., GAN, VAE. We fine-tune existing model as a foundation to generate a new model, with less training effort. LLM and Diffusion are both generative, probabilistic models. ChatGPT is a product powered by GPT model (belongs to LLM family). Stable Diffusion is a Diffusion model, and its sevond version learns pattern in a hidden box called latent space. Above models all use Transformers as the architecture. Transformers are a type of attention-based neural network. mindmap root((Deep Learning)) models discriminative model K nearest Logistic regression SVM Random Forest ... generative model deterministic CNN ... probabilistic VAE GAN LLM Diffusion architectures CNN LSTM GAN VAE ... Transformer BERT GPT ... ","permalink":"https://pps43.github.io/posts/asking_ai_about_ai/","summary":"按照目前AI在学术界、工业界推陈出新的速度，感兴趣的同学们纷纷表示：真的学不动啦！不要慌，AI老师来了~ 在本系列中，我不会提前学习预备知识，","title":"跟AI老师学AI（一）"},{"content":" \u0026ldquo;There are decades where nothing happens; and there are weeks where decades happen.\u0026rdquo; ― Vladimir Lenin\n基于大语言模型的AI在这个月带给人们的感受，用列宁的这句话概括再贴切不过了。作为普通人，去拥抱这些AI工具，就像会使用智能手机和搜索引擎；对人类来说，就像学会用电，学会用火。\n%%{init: { \u0026#39;logLevel\u0026#39;: \u0026#39;debug\u0026#39;, \u0026#39;theme\u0026#39;: \u0026#39;dark\u0026#39; } }%% timeline title Era of AI comes in 2023 2-7: Microsoft New Bing 3-12: Open AI ChatGPT 90% cheaper 3-15 : Open AI GPT-4 3-16 : Microsoft Copilot : Midjourney V5 : Google PaLM API 3-21 : Adobe FireFly : Nvdia GTC 3-22 : Github Copilot X : Google Bard 3-24 : Open AI ChatGPT Plugins 更新：4月以来，AI应用的新概念、新架构、新产品如寒武纪大爆炸一般涌现（AutoGPT 首当其冲），非人力所能穷举。 这个网站收录了大量AI工具，本文也会持续更新笔者常用、觉得好用的工具。\nFor General Purpose Open AI\u0026rsquo;s ChatGPT, and Plugins. GPT3.5 is free to use. Microsoft\u0026rsquo;s NewBing. It\u0026rsquo;s said to be powered by GPT4 (internal version). Google\u0026rsquo;s Bard. After trying many LLM, ChatGPT is still the best one to be professional and smart. But I still prefer asking different models to get different points of view. Some common tips when asking:\nRole play. act as .... Here is a collection of role-related prompts. Give template input-output. Tell chatgpt to anwser step by step. For Doc Edge + NewBing. Explain any webpage (including PDF) side by side. ChatDoc/ChatPDF, upload PDF and analyze. ⏳Microsoft\u0026rsquo;s Copilot. For Software Development phind, the AI search engine for developers. Cursor editor, or vscode plugin CodeCursor, read/write current document/code, FREE to try. Old Github Copilot (based on OpenAI\u0026rsquo;s CODEX), costs $10/mo after 60d trial. ⏳Github Copilot X ⏳Copilot for Docs, used to learn a SDK/framework/API, can based on private content. The gist to generate code is, to describe a single-responsibility function to let AI generate, rather than a function with long description of chained operations.\nFor 3D/2D Art Stable-Diffusion (SD) web-ui, totally free and opensource, run model locally on PC.\nDownload/Share models on civitai/Hugging face Use ControlNet (Github )to add more controll on specific SD model. Use LoRA (Low-rank adaption) to train faster with less memory. Use Text Inversion to train with amazingly small output. Use [DreamBooth] to train if you need to be really expressive. Midjourney, famous for its artistic style, 25 times FREE try.\nBuilt on Discord Bot, thus you can use Official API or thirdparty lib to automate the flow. Adobe\u0026rsquo;s Firefly\nOpen AI\u0026rsquo;s DALL-E-2, generates image with natural language and long prompts, but limited-access and less control.\nBing\u0026rsquo;s Image Creator, generate image with natural language, and free to try.\nFor Music Mubert Soundraw.io Want more power? If you want to:\ntrain your own AI based on these models know the strength and weakness of current AI models know why \u0026amp; how Generative AI works, mathematically Here are my personal ideas:\nFor text, play with LLaMA/llama.cpp, or its fined tuned version Alpaca/Alpaca-LoRA. For image, play with Stable-Diffusion and its plugins. They can run on PC/Mac. Weakness of current LLM models: math; chain of decision. But they are improving. \u0026ldquo;Dive into Deep Learning\u0026rdquo; by 李沐。中文版《动手学深度学习》 Hardware considerations Training on cloud is cheaper and least effort to start. (Google\u0026rsquo;s Colab is even FREE) Training on local hardware, if use multiple GPUs (with NVLink), traffic bandwidth between GPUs is the botthleneck. (DGX A100 specs: 8xA100 GPUs, total 640GB VRAM, 600GB/s GPU-to-GPU bandwidth.) ","permalink":"https://pps43.github.io/posts/ai_toolkit_for_dev/","summary":"\u0026ldquo;There are decades where nothing happens; and there are weeks where decades happen.\u0026rdquo; ― Vladimir Lenin 基于大语言模型的AI在这个月带给人们的感受，用列宁的这句话概括再贴切不过了。作为普通人，去拥抱这些AI工具，","title":"Generative AI Toolkit (5.12)"},{"content":"市面上以DevOps为主题的书，以及和项目攻关的影视作品有不少了，但这本小说读起来依然紧张刺激。除了揭示管理现代IT组织与管理传统工厂的共通之处，书里更强调了以一种全局的视角来重新看待自己的工作环境，和自己在工作中扮演的角色，并且，其包含的问题分析方法、实践方法也或多或少可用于个人效能的优化。\n下面是一些书摘和简评。\n面对压力和现实 比尔，我知道你没有申请这个职位，但公司已命悬一线，我需要你来帮助我拯救这家伟大的公司。我能指望你吗？还没来得及再次礼貌谢绝，我突然听到自己说“可以，你可以指望我。”我慌了，强迫自己住嘴，以免做出更多愚蠢的承诺。……“我会尽力的，还有，能不能请你至少解释一下，为什么在这个位子上的人都干不长？你最希望我做什么，最不希望我做什么？”\n临危受命时，一定要弄清楚领导的意图和前任失败的原因。\n我还来不及回应，莎拉就大声说：这恰恰表明，比尔及其团队缺乏对于紧迫性的必要认知。追求完美是成事的大敌，比尔，我们可没有闲工夫为了迎合你的黄金标准而精雕细琢……难道这不是有点太轻率、太不公平了吗？但莎拉不屑一顾的说：我相信决定已经做出了。……接下来的9天里，我们所有人都要熬夜加班了。这种全员出动的工作状态是IT人生活的一部分，但是想到我们又得因为其他人疏于计划 而不得不奋力拼搏，我还是有些恼火。\n在市场负责人莎拉拿出一切为了项目这个尚方宝剑时，由于没有实际数据支撑，只因为道理而不去做是不够的，所以只能先忍下来。反倒是不顾实际情况强行推进项目发布的莎拉，得到了CEO史蒂夫的支持。因为CEO更关心股价、以及董事会对他的看法！\n我设法复述那些缜密理性、条理分明的论点，他们是我花了整个周末的事件排练的……我一边说一边不断观察史蒂夫，到目前为止，他一直面无表情。……史蒂夫愤怒的回答：什么优先级高不高的狗屁问题？……我在心里默数三下才开口：当然，我表达的不够清楚，……我们的基础架构太过脆弱……好吧，我们会尽最大努力，但我要郑重声明，我们的人手严重不足，无法高质量完成其中任何一项工作，更别说全部了。……比尔，凤凰项目已经超支1000万美元，我们必须马上得到正向现金流。增加任何预算都是不可能的，如果会有什么调整，我们可能还得在你的部门减掉几个人。……离开的时候，我把花费整个周末时间准备的演示稿扔进了垃圾桶。\nCEO有他的计算方式和危机视角，所以主角上来摆事实说道理不会得到支持。\n公司高管强迫我的工程师优先执行他们的命令，这完全是胡闹。我（对布伦特）补充道：如果有人为了凤凰项目之外的事和你联系，就把他们推给韦斯（直接上级），让他去对付那帮笨蛋。无论如何都要想办法改正大家直接来找你帮忙的坏习惯。我允许你把电话设成静音，把状态设置成你没空。随便怎么样都行。\n布伦特是一名对系统了解最多的明星员工，所有重要的系统变更都需要他帮忙，但他就像一个黑盒，是系统的约束点。首要任务是发现并保护系统的约束点。\n我惊讶的目瞪口呆：史蒂夫，情况得有多糟糕你才肯推迟这次发布？我告诉你这次是运行将是非常鲁莽的冒险！……虽然很不情愿，但我还是觉得自己欠公司最后一搏，去阻止这次疯狂的行动。……（强行发布后）……史蒂夫停下脚步，用手指着我的前额说：我对责任的理解，比你一辈子学的还要多！我受够了你整天嚷嚷着天要塌了，时候在高高兴兴地说‘我早就告诉过你了’。你得带着实际的解决方案来找我。……我需要业务部门告诉我，他们不再受部门IT部门的钳制。我担任CEO依赖，一直都听到这样的投诉，IT拖累了每一项重要举措。\n原来是这种发酵很久的情绪带来了偏见，导致史蒂夫讨厌比尔的稳扎稳打，偏爱莎拉的冒进。\n（史蒂夫讲述自己的个人经历和弱点，并鼓励会上的每一个人都这么做）展现自己脆弱的一面有助于建立起信任的基础。\n约翰气急败坏的说：你以为你是谁？我在努力保持这家公司的安全，让那些审计师离得远远的！我……得了吧，只会帮倒忙的CISO先生。埃瑞克打断他说，正如你刚才看到的，不用你出手，这家公司就能让审计师离得远远的。你就像个管道工，不知道自己在为一架飞机服务，更别说了解飞行路线，或者航空公司的营业状况了。……你真的不明白，是不是？无极限零部件公司最大的风险是停业破产，而你似乎一心想用你那些不周全的考虑和无关紧要的技术细节，让他加速倒闭。怪不得你会被边缘化！……\n约翰身上有几个问题：\n没有理解总目标。数据安全是重要，但公司和业务都要黄了，保证数据安全只是空谈而已。 没有理解业务全流程。事后他才知道即使前序的IT系统中有各种安全隐患，但后续每一笔交易都有人工审核，所以审计师并不会来找麻烦。 没有真正理解自己的职责和能力如何助力于总体目标。所以他倡导的数据安全在其他人看来只有妨碍作用。他在该阶段真正的作用在于用经验和能力减少其他部门在安全上的无效努力。 克里斯首先回答：我之前就说过，就连次要的漏洞修复都问题重重，我们不能承受每月一次的发布……史蒂夫回答：成败就看这个季度。我们向世人许诺过，会在上个月把凤凰弄出来。……我们没有时间了。我对克里斯说，如果你说凤凰团队应该放缓速度，我不会有异议。但是，我们仍然要想办法满足史蒂夫的要求，如果我们不能再凤凰的框架内做成这件事，也许可以在凤凰之外做到。我提议可以从凤凰主团队分出一小队人，组建特别行动队。\n老项目老流程积重难返，这里提供了一种减少掣肘的思路。后文能看到，特别行动队奏效了，而且其优秀的工作流还被原凤凰团队逐步借鉴，形成反哺。\n建立认知 半成品是个隐形杀手。\n因此，管理任何一家工厂最关键的机制之一，就是工作任务和原材料的发布。没有这个机制就无法控制半成品。为了停止半成品在工作流中堆积，即使其他人闲得无聊，也不应该在瓶颈已经达到饱和的情况下，继续制造半成品。\n在瓶颈之外的任何地方做出的改进都是假象。\n作为IT运维部的副总裁，你的工作时确保形成一条迅速、可预测、持续不断的计划内工作流，从而向业务部门交付工作价值，同时尽可能降低计划外工作的影响和破坏。我不管每个人觉得自己的项目有多重要，我们要知道的是，该项目能否提高我们在约束点上的工作能力。\n实际上有四种类型的工作：来自业务方的、自身基础架构的、操作变更、计划外工作。\n计划外工作是恢复性工作（比如屎山代码出BUG后的救火），占用你的时间并阻碍完成前三种正向产出的工作。如果不加控制，技术债务将导致公司里能够唯一完成的工作就是计划外工作。\n流程是用来保护人的。\n根据韦斯讲的故事，我们甚至都不该让布伦特碰到键盘，他可以告诉大家应该输入什么，但在任何情况下，都不准他做哪些我们无法在时候记录的事……每解决一个问题，我们的知识库里就会多一篇关于如何解决某个疑难杂症的文章，而且能够实施修复的人会越来越多。\n这里提到的解决疑难杂症的文章，类似我在微软工作时组内特别重视的postmortem，也类似达利欧在桥水特别推行的错误日志。目的是同样的错误绝不犯两次，而且下次其他人也可以处理。\n一旦通清楚最常出现的任务是什么，就需要建立起工作中心和工作路径。\n你必须跳出原来的专有领域，才能弄清楚整体的成功需要你的哪些工作来达成。\nIT是一种技能，就像能读会算一样。理解技术能够做什么，不能做什么，已经成为一家公司每个部门必须具备的核心竞争力之一。\n创建一个让人感觉无能为力的系统，使我们能对人类同胞做的最具破坏性的一件事——我们剥夺了他人控制自己成果的能力，甚至营造了一种文化，让人们因为害怕遭受惩罚、失败而不敢做正确的事。这制造了“习得性无助”的环境，人们变得不愿或无法采取行动来避免未来遇到同样的问题。\n三步建立高效的工作流 目标：流量最大化；可灵活应对调整。\n第一工作法 明确价值链。从最终的绩效指标反推，其实现依赖什么，以及不满足时有什么风险。 最大优化正向工作流。 让等待时间可视化。在工厂的流水线上在哪里出现拥堵或空转显而易见，但IT或日常生活中很容易忽略（又叫暗时间）。Kanban是一种比较好的方式，注意只有在生产环境里成功运行起来、或开始产生价值的时候，才能算“完成”。 减少中断。生产中断在制造业里显眼且代价极高，所有的半成品都将报废。但技术工作者很容易被打断，因为后果不可见。通过严格限制多任务的数量、新任务的插入减少打断的次数。 杜绝缺陷向下游传递。发现难题，群策群力，建立机制而不是以后再说。 减小交付的内容大小和等待间隔。 持续识别、改善约束点。约束点可以是一个人，或者大家都倚赖的同一种资源、前置步骤。以DevOps为例，通常要依次优化以下约束点：1、环境搭建；2、代码部署；3、准备和执行测试；4、架构耦合。 消除浪费。例如：1、半成品（文档、变更单等）；2、多余工序（对后续流程无价值）；3、任务切换；4、资源竞争和等待；5、非标准或手动操作。 第二工作法 快速、持续的获得反馈。否则没人敢在一个复杂系统中放心的工作（不用担心自己的某一个操作在将来搞坏系统中另一个本不相关的功能）。 仍以微软为例，Substrate仓库里有多个M365相关的产品，约5000+工程师维护着上百GB的源码文件，即使穷尽一生也没有人能充分了解这样一个已经存活几十年的庞然巨物。然而这样一个系统的迭代速度却非常惊人，保障这个工作流的其中一个方式是：\n每一次代码提交都会触发多种自动化测试和模拟部署，在几分钟到几十分钟内告诉你是否可以将代码合入主干。 同时会自动@所有相关模块的负责人在DevOps系统中进行Review，直到所有利益相关者同意合入。 第三工作法 建立具有创意和高可信度的文化。它强调每个人都是持续学习者，必须勇于承担风险，通过科学的方式改进。彼此分享经验，经验积累沉淀。\n将日常工作的改进制度化 将局部的优秀经验全局化 领导层为团队创造学习条件，领导力并不体现在做出的所有决定都是对的。 ","permalink":"https://pps43.github.io/posts/notes_on_phoenix_project/","summary":"市面上以DevOps为主题的书，以及和项目攻关的影视作品有不少了，但这本小说读起来依然紧张刺激。除了揭示管理现代IT组织与管理传统工厂的共通","title":"凤凰项目"},{"content":" 近日读完《贫穷的质感·王梆的英国观察》（豆瓣读书，Goodreads）一书后，将只言片语组合起来作一点记录。此书说了很多英国普通人的事情、社会传统，但相信我们读起来应该不会太陌生。透过诸多生活中的观察，自然引申出养老、医疗、社会制度、逆全球化等话题。\n只言片语 英国政府曾推出大量廉租房，老旧了便拿来卖钱。由于是市面价格的一半，非常受炒房客的欢迎。有钱人买来继续出租，租金比原来还要高。但由于政府不再负责修缮，这些房子逐渐变得又贵又脏。\n斯蒂芬·阿姆斯特朗指出：穷人不是贫困的罪魁祸首，而是他的产物。贫困也不可能通过自律自愈，紧缩只会导向更极致的贫穷。\n19世纪的改革家为底层人民指出的通往中产之路是五条箴言：勤劳，坚持，节俭，审慎，自力更生。但社会现实是，权贵们掌握着话语权，一旦你陷入贫穷，此前的辛勤付出全不算数，社会对你的困顿只有一条解释：懒惰。\n私人养老院的比例急剧上升，很多投机商大举投资养老院，经营不善则扔给政府逃之夭夭。收费998英镑一周。没钱了怎么办？可以卖房或者先住，死后房子被收走。但一般房产的价格只够住四年。工资低雇员少，虐待事件因此极为普遍。几乎每所大学都在想方设法取消全职合约，因为这样就能省掉不少职业养老金了。\n脱欧是这么多年来他们（农民，流水线工人等等）所获得唯一一次发声，是他们想象中对抗外来移民、以及国际垄断资本主义带来的困苦生活状态的一种方式。\nKeep calm and carry on. 这句话自维多利亚时代就被英国社会视为行为典范。恐慌是可耻的。正如贫穷是可耻的。疫情后，一部分人过上了在家办公的生活，另一部分人则成为“前线工人”（看护，餐饮工作等）。自封城后，人们对前线工人的赞美开始层出不穷，但这改变不了他们的高死亡率。\n1863年，古典自由主义者引领了废奴运动并获得巨大成功。全球化后，新自由主义者（大资本家）却用自由市场重新包装了蓄奴主义，且丝毫不觉有任何道德负担。吊诡的是，许多被损害的人也保持着同样的道德优越感：自由市场是完美的，穷人是不幸的，因为他们天生智商低下。富人是优胜劣汰的产物，通过创造财富缴纳税金，连同穷人一起受益。\n相关阅读 Why Poverty? (PBS documentary films) Poor Economics (中译名《贫穷的本质》)，豆瓣读书, Goodreads ","permalink":"https://pps43.github.io/posts/notes_on_texture_of_hard_times/","summary":"近日读完《贫穷的质感·王梆的英国观察》（豆瓣读书，Goodreads）一书后，将只言片语组合起来作一点记录。此书说了很多英国普通人的事情、社","title":"贫穷的质感（王梆）"},{"content":" 本文总结自Ray Dalio: How the Economic Machine Works，原视频地址\n核心概念简述 什么是交易 买方使用货币、信用（也叫信贷）向卖方交换商品、服务、金融资产。 交易首先是由人的天性驱动的。 买方的支出总额（而不是其他）是经济的驱动力，所有的经济周期和动力都是交易造成的。 交易的主体通常有：个人、企业、银行、政府。 政府如何参与交易 政府其实同时是最大的买方和卖方。 政府主要由两部分：中央政府，负责收税；中央银行，负责花钱。 中央银行通过利率和印钱控制经济中的货币和信用（信贷数量）。 什么是信贷 信贷也是一种交易。比如你找银行借钱，你是借款人，银行是贷款人。你是交易的卖方，银行是买方。 这种交易的特殊之处在于：交易是延迟完成的，即借款人保证将来偿还贷款和利息，直到那个时候，交易才算完成。 交易未完成前的状态，即债务。债务是贷款人的资产，借款人的负债。 只有交易完成时，这些资产和负债才会消失。 什么是价格 $$ 价格 = \\frac{买方支出总额}{产销总量} =\\frac{(货币 + 信贷)} {产销总量} $$\n什么是市场 一种市场，包含同一种商品的所有买方和所有卖方。有千千万万种商品或服务对应千千万万种市场。\n什么是经济 全部市场的全部交易统称为经济。\n经济形势变化的三条脉络 这三个相对独立的因素叠加起来，构成经济形势的变化：\n生产率的提高（近似线性） 债务小周期（5~8年） 债务大周期（75~100年） 深入经济周期 经济为什么依赖信贷 简而言之，因为借款人通过信贷可以增加自己的支出，而支出是经济的驱动力。在没有信贷的社会中，增加支出的唯一方式是增加生产。由于信贷可以凭空产生，支出可以超越当前生产，所以能让经济注入更多活力。\n更具体的说，交易双方中，A的支出是B的收入，A支出增加等于B收入增加，B偿还能力提升，信贷能力也会提升，B的支出可以进一步增加，在另一场交易中，B的支出增加等于C的收入增加……产生循环。不过要注意，借钱实质是向未来某一时刻的自己借钱，即未来那个时刻自己的收入减掉消费必须足够还钱才能保证交易最终的有效性。\n经济上下起伏不取决于人们多么善于创新或勤奋工作，而看信贷的总量。而人的天性和借贷机制决定了信贷总量一定是波动的。\n短期信贷周期为什么出现 考虑单一商品的情况。如果支出（消费）或者收入（消费是另一个人的收入）的增长速度超过所出售商品的生产速度，商品价格就会上涨。央行为了防止通货膨胀，会提高利率。利率直接影响人们贷款和借款意愿——这也是限制支出的唯一因素。还贷增加造成可支配的支出减少，商品价格下跌。\n当信贷易于获得则经济扩张，信贷不易获得则经济收缩，这个周期由央行主导，一般5~8年。\n长期信贷周期为什么出现 经历一个短期周期后，经济增长和债务规模都会超过前一个周期。债务规模的扩大其实正是人的天性：更喜欢消费而不是还钱。因此经历若干短周期后，债务增加的速度其实会超过收入（虽然收入也在增加）。到那时，社会总债务会变得过重而导致支出、收入、信用的全面下降，这个过程叫去杠杆化。\n社会总债务：政府债务、居民债务、非金融企业债务。社会总债务过重一般是指超过GDP的好几倍。\n去杠杆化过程开始后，会出现资产价格下跌、企业破产、信贷消失、无法正常还贷，只能变卖资产，进一步造成资产价格下跌，形成恶性循环，且无法通过降低利率摆脱（降到0以后就到底了）。例如欧美1929年、2008年，日本1989年。\nflowchart LR 资产价格下跌 --\u0026gt; 企业或个人破产 --\u0026gt; 信贷消失 --\u0026gt; 变卖资产 -.-\u0026gt; 资产价格下跌 根据具体情况的不同，该周期可能持续75~100年。\n有哪些方式解决债务过重问题 衡量债务负担是否过重：\n$$ 债务负担 = \\frac{债务}{收入} $$\n解决债务过重的四种主要手段：\n所有交易主体削减支出；\n因为A的支出是B的收入，B收入也下降了，那么B的债务负担更重，所有人更痛苦。会演变成通货紧缩。 例如企业为了削减成本造成大量人口失业。 通过判定违约和重组减少债务；\n大量借款人无法偿还即债务违约后，贷款人会向银行索要存款，造成挤兑，银行自身也会违约。这就叫经济萧条，即所有人都感觉自己的资产蒸发了。 比债务违约稍好一点的方式是债务重组，即还款减少或延期或利率降低。 不论哪种方式，由于A的债务是B的资产，债务消失或减少，意味着B的资产减少。依旧会演变成通货紧缩。 政府财富再分配；\n在去杠杆化的过程中，伴随着失业人口上升，因此政府支出变多甚至财政赤字，必须收更多的税或发行债券。 向谁融资或征税呢？通常是富人。但容易引发社会动荡。如果是国与国之间，会引发战争。 央行增发货币；\n前文提到央行的两个手段：利率和印钞。利率降低到0之后，只能印钞。 印出的钞票只能用来买入金融资产和政府债券。前者可以保住金融资产（例如股市）的价格，因此提高了持有人的信用（但仅仅对持有金融资产的人有用），后者其实是把印出的钱借给政府，由政府通过救济金和刺激计划增加人们收入，实质上是将经济系统分散的总债务，集中到政府的头上。 增发的货币刚好抵消贷款的降幅，就不会引发通货膨胀（参考前文说过的价格公式）。温和的通货膨胀本身对经济并不有害。但增发太猛会导致恶性通货膨胀，例如1920年的德国。 结合具体情势，通过巧妙地组合使用上述四种手段，才可以做到和谐的去杠杆。也不要太悲观，因为和谐的去杠杆化过程比信用扩张时期更好，因为此时经济是在自然缓慢增长的，夯实根基。\n反思 上述模型大致可以判断当前我们处于哪个阶段，预测未来大趋势如何。 上述模型解释了经济周期的必然性：现代社会的经济发展依赖信贷，信贷依赖机制和人性，机制有一定的调整空间（但交易延迟完成和要连本带利是刚性的）、人性则不可避免的包含贪婪、恐惧、喜欢消费而不是还钱、从众…… 上述模型对于个人的启发意义： 不要让债务的增长速度超过收入，因为最终会让债务把你压垮； 不要让收入的增长速度超过生产率，因为最终这会让你失去竞争力； 尽一切努力提高生产率，因为它在长期起最关键的作用。 ","permalink":"https://pps43.github.io/posts/how_the_economic_machine_works/","summary":"本文总结自Ray Dalio: How the Economic Machine Works，原视频地址 核心概念简述 什么是交易 买方使用货币、信用（也叫信贷）向卖方交换商品、服务、金融资产。 交易首先","title":"经济机器如何运行（达利欧）"}]