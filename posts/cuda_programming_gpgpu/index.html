<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>GP-GPU编程：CUDA介绍 | 波波沙🏠</title>
<meta name=keywords content><meta name=description content="
本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。"><meta name=author content><link rel=canonical href=https://pps43.github.io/posts/cuda_programming_gpgpu/><link crossorigin=anonymous href=/assets/css/stylesheet.da461cdc6aa5b1045299cab0ebd07edbb2f1e481e0c7ae775d260fc5af887327.css integrity="sha256-2kYc3GqlsQRSmcqw69B+27Lx5IHgx653XSYPxa+Icyc=" rel="preload stylesheet" as=style><link rel=icon href=https://pps43.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://pps43.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://pps43.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://pps43.github.io/apple-touch-icon.png><link rel=mask-icon href=https://pps43.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://pps43.github.io/posts/cuda_programming_gpgpu/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css integrity="sha512-0aPQyyeZrWj9sCA46UlmWgKOP0mUipLQ6OZXu8l4IcAmD2u31EPEy9VcIMvl7SoAaKe8bLXZhYoMaE/in+gcgA==" crossorigin=anonymous referrerpolicy=no-referrer><script src=https://unpkg.com/mermaid/dist/mermaid.min.js></script><script>const config={startOnLoad:!0,theme:"neutral",themeVariables:{lineColor:"#aaaaaa"},flowchart:{useMaxWidth:!1,htmlLabels:!0}};mermaid.initialize(config),window.onload=()=>{window.mermaid.init(void 0,document.querySelectorAll(".language-mermaid"))}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-7GDH7EZ6GL"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7GDH7EZ6GL")}</script><meta property="og:url" content="https://pps43.github.io/posts/cuda_programming_gpgpu/"><meta property="og:site_name" content="波波沙🏠"><meta property="og:title" content="GP-GPU编程：CUDA介绍"><meta property="og:description" content=" 本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-02-28T00:00:00+00:00"><meta property="article:modified_time" content="2015-02-28T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="GP-GPU编程：CUDA介绍"><meta name=twitter:description content="
本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://pps43.github.io/posts/"},{"@type":"ListItem","position":2,"name":"GP-GPU编程：CUDA介绍","item":"https://pps43.github.io/posts/cuda_programming_gpgpu/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"GP-GPU编程：CUDA介绍","name":"GP-GPU编程：CUDA介绍","description":" 本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。\n","keywords":[],"articleBody":" 本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。\n简介 历史 近30年来，提升CPU计算性能的主要方法就是提升时钟频率。此方法在目前的硅基半导体工艺下已进入瓶颈，转而用“并行”来提升计算性能（例如多核）。\n自1980年代起，一家名为Silicon Graphics的公司在业界推广OpenGL用于渲染三维图像，获得了广泛支持。NVIDIA、ATI等公司也开始对计算机3D图形计算加速进行研究，并将此硬件设备称为“GPU”以区别于传统的CPU。GPU由于其结构特点，具备强大的并行计算能力。（1999年，GPU的始祖GeForce 256横空出世。2002年完整支持DX9的王者Radeon 9700Pro正式开启了GPU的众神时代，Age of Gods. 显卡爱好者可以看看此文：视觉时代的回响 GPU十年历史追忆。）\n在很长一段时间里，利用GPU进行渲染是通过OpenGL和DirectX进行的。人们发现传给GPU进行像素点渲染的颜色、纹理坐标等信息其实可以是任何数据，即GPU可以用于通用计算（General Purpose GPU）。然而当时的GPU有着难以在显存任意位置进行读写、GPU本身也不具备浮点计算能力、GPU难以debug等严重缺点。更糟的是，必须使用一种叫“shader language”的编程语言，利用OpenGL和DirectX提供的API对GPU进行操作。利用GPU进行通用计算的巨大的学习成本，使得研究人员望而却步。\n对于上述硬件缺点，NVDIA推出了基于CUDA架构的GPU，如2006年上市的高端卡GeForce 8800 GTX；对于上述软件缺点，NVDIA在C的基础上进行扩展，并在GeForce 8800 GTX上市后几个月后公布CUDA C语言及相应的编译器用于GPGPU的编程。\n现状 性能上，就个人电脑来说，目前的顶级CPU，主频也很难上4GHz，而核心数量很难达到16个（计算能力约64GFLOPS）。而稍微高端点的GPU早就超过3000GFLOPS（以GTX 690为例，核心频率约1GHz，3072个核心）。国外已有建立在Tesla k40集群上的超算中心。下面一图以蔽之吧。 GPGPU应用：耳熟能详的GPU应用诸如：视景仿真、视频渲染。以及石油勘探、环境科学、航空航天和流体力学计算等领域。举几个典型且较新的例子：医疗成像。智能汽车。深度学习。 概念 硬件 Device, Host\nCPU和内存（host memory）是host，GPU和显存（device memory）是device。 SM, SP\nSM：Stream-Multiprocessor，俗称“大核”。SP：Stream-Processor，俗称“小核”。 Global memory\n就是通常意义上的显存。 Shared memory\n为同一个block中若干threads所共享。 存取非常快，可看作user-managed cache。CUDA C中的关键词：__shared__ Constant memory\n并行层次 并行是一个概念，可以用在不同的层面。CUDA中从高到低有以下几个层次：\nstream -\u003e grid -\u003e block -\u003e (warp) -\u003e thread.\n并行层次与存储层次是对应的。\nthread 并行的基本单位。同一个block中的thread通过shared memory共享数据。同一个block中的thread通过__syncthreads()同步，具体见下一节。 warp In the world of weaving, a warp refers to the group of threads being woven together into fabric. In the CUDA Architecture, a warp refers to a collection of 32 threads that are “woven together” and get executed in lockstep. At every line in your program, each thread in a warp executes the same instruction on different data. When it comes to handling constant memory, NVIDIA hardware can broadcast a single memory read to each half-warp. A half-warp—not nearly as creatively named as a warp—is a group of 16 threads: half of a 32-thread warp. If every thread in a half-warp requests data from the same address in constant memory, your GPU will generate only a single read request and subsequently broadcast the data to every thread. If you are reading a lot of data from constant memory, you will generate only 1/16 (roughly 6 percent) of the memory traffic as you would when using global memory. 最大支持512个threads。只用一个block不能充分利用GPU的资源。 grid We call the collection of parallel blocks a grid. 同一个grid中的所有thread都执行相同参数的核函数。 stream A stream is a sequence of commands (possibly issued by different host threads) that execute in order. this behavior is not guaranteed and should therefore not be relied upon for correctness (e.g., inter-kernel communication is undefined). 不同stream可执行不同参数的核函数。 通信机制 Inter-thread level\nshared memory. 要求是同一个block中的threads。 内置函数 __syncthreads(). 作用是当某个线程执行到该函数时，进入等待状态，直到同一线程块（Block）中所有线程都执行到这个函数为止。 原子操作。可以跨block。 Inter-block level\nInter-stream level\n实践 环境搭建 采用64位win7 + visual studio 2013 + cuda toolkit 6.5 。早期的cuda环境需要下载cuda toolkit、drivers、cuda SDK，现在全部打包到一起了。Cuda Toolkit 6.5下载地址：官网 关于软硬件兼容性的问题，2010年的老显卡（指笔者的Quadro NVS 3100M 。怎么样，没听过吧，说多都是泪……此卡介于G210M~G310M之间）仍可以安装 6.5 版，基本可以放心下载。 完整的搭建过程参考官方文档。\n常见问题 warning: C4819\n只需在项目properties-\u003econfiguration properties-\u003eCUDA C/C++的Additional options那里加一行：-Xcompiler /wd4819 error：expected and expression (不能识别\u003c\u003c\u003c)\n首先检查出错的代码文件的属性中，item type是不是CUDA C/C++。如果是，则没有大碍，只是VS的C/C++文本编辑器认为有错，编译器可以通过。这里提到一种自定义宏的方法消除这个小bug。 error：addKernel launch failed: invalid device function\n常用工具 deviceQuery.exe\nCUDA Samples中自带的检测显卡信息的工具。可以方便的查看显卡的基本信息。如： 型号 Compute capability 核心数量（大核SM、小核SP） 时钟频率 global memory const memory shared memory/block 最大threads、block、grid限制等 bandwidthTest.exe\nCUDA Samples中自带的测试Device和Host之间带宽的工具。还有个重要功能是搭建CUDA环境后验证是否正常运转（看最后Result是否为PASS） Visual Profiler\n","wordCount":"2462","inLanguage":"en","datePublished":"2015-02-28T00:00:00Z","dateModified":"2015-02-28T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://pps43.github.io/posts/cuda_programming_gpgpu/"},"publisher":{"@type":"Organization","name":"波波沙🏠","logo":{"@type":"ImageObject","url":"https://pps43.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://pps43.github.io/ accesskey=h title="波波沙🏠 (Alt + H)">波波沙🏠</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://pps43.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://pps43.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://pps43.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://book.enginew.cn/ title=BookOfGameDev><span>BookOfGameDev</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">GP-GPU编程：CUDA介绍</h1><div class=post-meta><span title='2015-02-28 00:00:00 +0000 UTC'>February 28, 2015</span>&nbsp;·&nbsp;5 min</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e7%ae%80%e4%bb%8b aria-label=简介>简介</a><ul><li><a href=#%e5%8e%86%e5%8f%b2 aria-label=历史>历史</a></li><li><a href=#%e7%8e%b0%e7%8a%b6 aria-label=现状>现状</a></li></ul></li><li><a href=#%e6%a6%82%e5%bf%b5 aria-label=概念>概念</a><ul><li><a href=#%e7%a1%ac%e4%bb%b6 aria-label=硬件>硬件</a></li><li><a href=#%e5%b9%b6%e8%a1%8c%e5%b1%82%e6%ac%a1 aria-label=并行层次>并行层次</a></li><li><a href=#%e9%80%9a%e4%bf%a1%e6%9c%ba%e5%88%b6 aria-label=通信机制>通信机制</a></li></ul></li><li><a href=#%e5%ae%9e%e8%b7%b5 aria-label=实践>实践</a><ul><li><a href=#%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba aria-label=环境搭建>环境搭建</a></li><li><a href=#%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98 aria-label=常见问题>常见问题</a></li><li><a href=#%e5%b8%b8%e7%94%a8%e5%b7%a5%e5%85%b7 aria-label=常用工具>常用工具</a></li></ul></li></ul></div></details></div><div class=post-content><blockquote><p>本文简要介绍了利用GPU进行通用计算的历史和方法，以NVDIA家的CUDA架构为例，介绍GPGPU编程的重要概念和简单实践。希望能够在浩如烟海的网络资料之外，给像我这样的初学者提供一些清晰的参考。CUDA C的学习资料在文末给出，NVDIA的官方文档干净友好，听说社区生态也堪称典范，好感度+1。</p></blockquote><h1 id=简介>简介<a hidden class=anchor aria-hidden=true href=#简介>#</a></h1><h2 id=历史>历史<a hidden class=anchor aria-hidden=true href=#历史>#</a></h2><p>近30年来，提升CPU计算性能的主要方法就是提升时钟频率。此方法在目前的硅基半导体工艺下已进入瓶颈，转而用“并行”来提升计算性能（例如多核）。</p><p>自1980年代起，一家名为Silicon Graphics的公司在业界推广OpenGL用于渲染三维图像，获得了广泛支持。NVIDIA、ATI等公司也开始对计算机3D图形计算加速进行研究，并将此硬件设备称为“GPU”以区别于传统的CPU。GPU由于其结构特点，具备强大的并行计算能力。（1999年，GPU的始祖GeForce 256横空出世。2002年完整支持DX9的王者Radeon 9700Pro正式开启了GPU的众神时代，Age of Gods. 显卡爱好者可以看看此文：<a href=https://news.mydrivers.com/1/276/276298.htm>视觉时代的回响 GPU十年历史追忆</a>。）</p><p>在很长一段时间里，利用GPU进行渲染是通过OpenGL和DirectX进行的。人们发现传给GPU进行像素点渲染的颜色、纹理坐标等信息其实可以是任何数据，即GPU可以用于通用计算（<code>General Purpose GPU</code>）。然而当时的GPU有着难以在显存任意位置进行读写、GPU本身也不具备浮点计算能力、GPU难以debug等严重缺点。更糟的是，必须使用一种叫“shader language”的编程语言，利用OpenGL和DirectX提供的API对GPU进行操作。利用GPU进行通用计算的巨大的学习成本，使得研究人员望而却步。</p><p>对于上述硬件缺点，NVDIA推出了基于CUDA架构的GPU，如2006年上市的高端卡<a href=https://en.wikipedia.org/wiki/GeForce_8_series#GeForce_8800_Series>GeForce 8800 GTX</a>；对于上述软件缺点，NVDIA在C的基础上进行扩展，并在GeForce 8800 GTX上市后几个月后公布CUDA C语言及相应的编译器用于GPGPU的编程。</p><h2 id=现状>现状<a hidden class=anchor aria-hidden=true href=#现状>#</a></h2><ul><li>性能上，就个人电脑来说，目前的顶级CPU，主频也很难上4GHz，而核心数量很难达到16个（计算能力约64GFLOPS）。而稍微高端点的GPU早就超过3000GFLOPS（以GTX 690为例，核心频率约1GHz，3072个核心）。国外已有建立在Tesla k40集群上的超算中心。下面一图以蔽之吧。</li><li>GPGPU应用：耳熟能详的GPU应用诸如：视景仿真、视频渲染。以及石油勘探、环境科学、航空航天和流体力学计算等领域。举几个典型且较新的例子：医疗成像。智能汽车。深度学习。</li></ul><h1 id=概念>概念<a hidden class=anchor aria-hidden=true href=#概念>#</a></h1><h2 id=硬件>硬件<a hidden class=anchor aria-hidden=true href=#硬件>#</a></h2><ul><li><p>Device, Host</p><ul><li>CPU和内存（host memory）是host，GPU和显存（device memory）是device。</li></ul></li><li><p>SM, SP</p><ul><li>SM：Stream-Multiprocessor，俗称“大核”。SP：Stream-Processor，俗称“小核”。</li></ul></li><li><p>Global memory</p><ul><li>就是通常意义上的显存。</li></ul></li><li><p>Shared memory</p><ul><li>为同一个block中若干threads所共享。 存取非常快，可看作user-managed cache。CUDA C中的关键词：<code>__shared__</code></li></ul></li><li><p>Constant memory</p></li></ul><h2 id=并行层次>并行层次<a hidden class=anchor aria-hidden=true href=#并行层次>#</a></h2><p>并行是一个概念，可以用在不同的层面。CUDA中从高到低有以下几个层次：</p><blockquote><p>stream -> grid -> block -> (warp) -> thread.</p></blockquote><p>并行层次与存储层次是对应的。</p><ul><li>thread<ul><li>并行的基本单位。同一个block中的thread通过shared memory共享数据。同一个block中的thread通过__syncthreads()同步，具体见下一节。</li></ul></li><li>warp<ul><li>In the world of weaving, a warp refers to the group of threads being woven together into fabric. In the CUDA Architecture, a warp refers to a collection of 32 threads that are “woven together” and get executed in lockstep. At every line in your program, each thread in a warp executes the same instruction on different data.</li><li>When it comes to handling constant memory, NVIDIA hardware can broadcast a single memory read to each half-warp. A half-warp—not nearly as creatively named as a warp—is a group of 16 threads: half of a 32-thread warp. If every thread in a half-warp requests data from the same address in constant memory, your GPU will generate only a single read request and subsequently broadcast the data to every thread. If you are reading a lot of data from constant memory, you will generate only 1/16 (roughly 6 percent) of the memory traffic as you would when using global memory.</li><li>最大支持512个threads。只用一个block不能充分利用GPU的资源。</li></ul></li><li>grid<ul><li>We call the collection of parallel blocks a grid. 同一个grid中的所有thread都执行相同参数的核函数。</li></ul></li><li>stream<ul><li>A stream is a sequence of commands (possibly issued by different host threads) that execute in order. this behavior is not guaranteed and should therefore not be relied upon for correctness (e.g., inter-kernel communication is undefined). 不同stream可执行不同参数的核函数。</li></ul></li></ul><h2 id=通信机制>通信机制<a hidden class=anchor aria-hidden=true href=#通信机制>#</a></h2><ul><li><p>Inter-thread level</p><ul><li>shared memory. 要求是同一个block中的threads。</li><li>内置函数 <code>__syncthreads()</code>. 作用是当某个线程执行到该函数时，进入等待状态，直到同一线程块（Block）中所有线程都执行到这个函数为止。</li><li>原子操作。可以跨block。</li></ul></li><li><p>Inter-block level</p></li><li><p>Inter-stream level</p></li></ul><h1 id=实践>实践<a hidden class=anchor aria-hidden=true href=#实践>#</a></h1><h2 id=环境搭建>环境搭建<a hidden class=anchor aria-hidden=true href=#环境搭建>#</a></h2><p>采用64位win7 + visual studio 2013 + cuda toolkit 6.5 。早期的cuda环境需要下载cuda toolkit、drivers、cuda SDK，现在全部打包到一起了。Cuda Toolkit 6.5下载地址：<a href=https://developer.nvidia.com/cuda-downloads>官网</a>
关于软硬件兼容性的问题，2010年的老显卡（指笔者的Quadro NVS 3100M 。怎么样，没听过吧，说多都是泪……此卡介于G210M~G310M之间）仍可以安装 6.5 版，基本可以放心下载。
完整的搭建过程参考官方文档。</p><h2 id=常见问题>常见问题<a hidden class=anchor aria-hidden=true href=#常见问题>#</a></h2><ul><li><p>warning: C4819</p><ul><li>只需在项目properties->configuration properties->CUDA C/C++的Additional options那里加一行：-Xcompiler /wd4819</li></ul></li><li><p>error：expected and expression (不能识别<code>&lt;&lt;&lt;</code>)</p><ul><li>首先检查出错的代码文件的属性中，item type是不是CUDA C/C++。如果是，则没有大碍，只是VS的C/C++文本编辑器认为有错，编译器可以通过。这里提到一种自定义宏的方法消除这个小bug。</li></ul></li><li><p>error：addKernel launch failed: invalid device function</p></li></ul><h2 id=常用工具>常用工具<a hidden class=anchor aria-hidden=true href=#常用工具>#</a></h2><ul><li><p>deviceQuery.exe</p><ul><li>CUDA Samples中自带的检测显卡信息的工具。可以方便的查看显卡的基本信息。如：<ul><li>型号</li><li>Compute capability</li><li>核心数量（大核SM、小核SP）</li><li>时钟频率</li><li>global memory</li><li>const memory</li><li>shared memory/block</li><li>最大threads、block、grid限制等</li></ul></li></ul></li><li><p>bandwidthTest.exe</p><ul><li>CUDA Samples中自带的测试Device和Host之间带宽的工具。还有个重要功能是搭建CUDA环境后验证是否正常运转（看最后Result是否为PASS）</li></ul></li><li><p>Visual Profiler</p></li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://pps43.github.io/posts/how_the_economic_machine_works/><span class=title>« Prev</span><br><span>经济机器如何运行（达利欧）</span>
</a><a class=next href=https://pps43.github.io/posts/je_suis_charlie/><span class=title>Next »</span><br><span>我是查理</span></a></nav></footer></article></main><footer class=footer><span>© 2016-2023 By 波波沙.</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>